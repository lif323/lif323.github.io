<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Posts on lif323</title><link>https://lif323.github.io/posts/</link><description>Recent content in Posts on lif323</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Fri, 07 Jun 2024 22:36:34 +0800</lastBuildDate><atom:link href="https://lif323.github.io/posts/index.xml" rel="self" type="application/rss+xml"/><item><title>Note on DynaMask ICML 2021</title><link>https://lif323.github.io/posts/post-4/</link><pubDate>Fri, 07 Jun 2024 22:36:34 +0800</pubDate><guid>https://lif323.github.io/posts/post-4/</guid><description>This paper is among the earliest works to learn a mask to measure the importance of each feature. Assuming a mask $M$, where $M_{t,i} \in [0, 1] $. When $M_{t, i} = 0$, this feature is irrelevant for black-box prediction. Conversely, when $M_{t, i}=1$, this feature is important for black-box prediction. The input $x$ is perturbed based on $M_{t, i}$. A simple perturbation method is as follows: $$ x'_{t,i} = x_{t,i} * M_{t, i} + b_{t,i} * (1 - M_{t, i}) $$ where $b_{t,i}$ is usually generated based on the data distribution.</description></item><item><title>Note on GSAT ICML 2022</title><link>https://lif323.github.io/posts/post-3/</link><pubDate>Thu, 30 May 2024 17:40:58 +0800</pubDate><guid>https://lif323.github.io/posts/post-3/</guid><description>This paper introduces GSAT methods for generating explanations in graph learning. GSAT is composed of the following parts:
$G = (A, X)$ $A$ is the adjacency matrix and $X$ is the node attributes. Let $V$ and $E$ denote the node set and the edge set.
Firstly, the extractor $g_{\phi}$ encodes the input graph $G$ via a GNN into a set of node representations $(h_u | u \in X)$. For any two nodes $v$ and $u$, an MLP layer maps the concatenation of their node representations to the probability $p_{u, v} \in [0, 1]$ of an edge existing between that corresponding pair of nodes.</description></item><item><title>Gumbel Softmax</title><link>https://lif323.github.io/posts/gumbel-softmax/</link><pubDate>Thu, 18 Apr 2024 11:24:57 +0800</pubDate><guid>https://lif323.github.io/posts/gumbel-softmax/</guid><description>What is Gubmel-softmax? Gumbel-softmax is an efficient gradient estimator for the non-differentiable sample from a categorical distribution.
Let $z$ be a categorical variable with class probabilities $\pi_1$, $\pi_2$, $\cdots$, $\pi_k$.
The Gumbel-Max trick is an efficient way to draw samples $z$ from a categorical distribution with class probabilities $\pi$: $$ z = \text{one\_hot}(\argmax_{i}\left[g_i + log \pi_i\right]) $$ where $g_1$, $\cdots$, $g_k$ are i.i.d samples drawn from Gumbel(0, 1). The Gubel(0, 1) distribution can be sampled by drawing $u \sim \text{Uniform}(0, 1)$ and computing $g = - \log (- \log (u))$.</description></item><item><title>Notes on the Paper NeurIPS 2023 Evaluating Post Hoc Explanations for Graph Neural Networks via Robustness Analysis</title><link>https://lif323.github.io/posts/notes-on-the-paper-neurips-2023-evaluating-post-hoc-explanations-for-graph-neural-networks-via-robustness-analysis/</link><pubDate>Sat, 13 Apr 2024 12:45:24 +0800</pubDate><guid>https://lif323.github.io/posts/notes-on-the-paper-neurips-2023-evaluating-post-hoc-explanations-for-graph-neural-networks-via-robustness-analysis/</guid><description>This paper focuses on the performance of evaluation methods of Post-hoc Explanations. Current prevailing evalution methods mainly inlcudes two types: Feature Removal methods and Generation-based methods.
This paper hones in on the evaluation of the effectiveness of Post-hoc Explanation evaluation methods. Predominantly, current methodologies fall into two primary classifications: Feature Removal and Generation-based approaches.
Feature Removal operates on the principle of excising salient features identified through explanation mechanisms. The merit of such explanations is quantified by the variance in the model&amp;rsquo;s output pre and post-feature extrication.</description></item></channel></rss>
<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Note Learning Perturbations ICML 2023 | lif323</title>
<meta name=keywords content><meta name=description content="This paper improves existing methods that provide explanations using trainable masks.
Inspired by methods for static data, the current approach uses fixed perturbations. However, this paper argues that this approach may not be suitable for time series data.
In this paper, their method not only has a trainable mask but also trainable perturbations.
Existing methods using fixed perturbations can be expressed as follows:

$$
\Phi(\mathbf{x}, \mathbf{m}) = \mathbf{m} \times \mathbf{x} + (1 - \mathbf{m}) \times g(\mathbf{x}), 
$$
where $g(\mathbf{x})$ is a function of the input. A possible definition is $g(\mathbf{x}) = \frac{1}{W}\sum_{t'=t-W}^{t}x_{t'}$."><meta name=author content><link rel=canonical href=https://lif323.github.io/posts/post-14/note-learningperturbations-2023/><link crossorigin=anonymous href=/assets/css/stylesheet.1d23bc8761bb8a516d01801663a24eeedbf97720019a7ddc0fc9ff29a2a8730d.css integrity="sha256-HSO8h2G7ilFtAYAWY6JO7tv5dyABmn3cD8n/KaKocw0=" rel="preload stylesheet" as=style><link rel=icon href=https://lif323.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://lif323.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://lif323.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://lif323.github.io/apple-touch-icon.png><link rel=mask-icon href=https://lif323.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://lif323.github.io/posts/post-14/note-learningperturbations-2023/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"\\[",right:"\\]",display:!0},{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],throwOnError:!1})})</script><meta property="og:title" content="Note Learning Perturbations ICML 2023"><meta property="og:description" content="This paper improves existing methods that provide explanations using trainable masks.
Inspired by methods for static data, the current approach uses fixed perturbations. However, this paper argues that this approach may not be suitable for time series data.
In this paper, their method not only has a trainable mask but also trainable perturbations.
Existing methods using fixed perturbations can be expressed as follows:

$$
\Phi(\mathbf{x}, \mathbf{m}) = \mathbf{m} \times \mathbf{x} + (1 - \mathbf{m}) \times g(\mathbf{x}), 
$$
where $g(\mathbf{x})$ is a function of the input. A possible definition is $g(\mathbf{x}) = \frac{1}{W}\sum_{t'=t-W}^{t}x_{t'}$."><meta property="og:type" content="article"><meta property="og:url" content="https://lif323.github.io/posts/post-14/note-learningperturbations-2023/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-07-07T15:00:05+08:00"><meta property="article:modified_time" content="2024-07-07T15:00:05+08:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Note Learning Perturbations ICML 2023"><meta name=twitter:description content="This paper improves existing methods that provide explanations using trainable masks.
Inspired by methods for static data, the current approach uses fixed perturbations. However, this paper argues that this approach may not be suitable for time series data.
In this paper, their method not only has a trainable mask but also trainable perturbations.
Existing methods using fixed perturbations can be expressed as follows:

$$
\Phi(\mathbf{x}, \mathbf{m}) = \mathbf{m} \times \mathbf{x} + (1 - \mathbf{m}) \times g(\mathbf{x}), 
$$
where $g(\mathbf{x})$ is a function of the input. A possible definition is $g(\mathbf{x}) = \frac{1}{W}\sum_{t'=t-W}^{t}x_{t'}$."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://lif323.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Note Learning Perturbations ICML 2023","item":"https://lif323.github.io/posts/post-14/note-learningperturbations-2023/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Note Learning Perturbations ICML 2023","name":"Note Learning Perturbations ICML 2023","description":"This paper improves existing methods that provide explanations using trainable masks. Inspired by methods for static data, the current approach uses fixed perturbations. However, this paper argues that this approach may not be suitable for time series data. In this paper, their method not only has a trainable mask but also trainable perturbations.\nExisting methods using fixed perturbations can be expressed as follows: $$ \\Phi(\\mathbf{x}, \\mathbf{m}) = \\mathbf{m} \\times \\mathbf{x} + (1 - \\mathbf{m}) \\times g(\\mathbf{x}), $$ where $g(\\mathbf{x})$ is a function of the input. A possible definition is $g(\\mathbf{x}) = \\frac{1}{W}\\sum_{t'=t-W}^{t}x_{t'}$.\n","keywords":[],"articleBody":"This paper improves existing methods that provide explanations using trainable masks. Inspired by methods for static data, the current approach uses fixed perturbations. However, this paper argues that this approach may not be suitable for time series data. In this paper, their method not only has a trainable mask but also trainable perturbations.\nExisting methods using fixed perturbations can be expressed as follows: $$ \\Phi(\\mathbf{x}, \\mathbf{m}) = \\mathbf{m} \\times \\mathbf{x} + (1 - \\mathbf{m}) \\times g(\\mathbf{x}), $$ where $g(\\mathbf{x})$ is a function of the input. A possible definition is $g(\\mathbf{x}) = \\frac{1}{W}\\sum_{t'=t-W}^{t}x_{t'}$.\nThey propose to replace these fixed functions with a neural network (NN) and train it with the mask. Their perturbation is defined as: $$ \\Phi(\\mathbf{x}, \\mathbf{m}) = \\mathbf{m} \\times \\mathbf{x} + (1 - \\mathbf{m}) \\times NN(\\mathbf{x}) $$ In extreme cases, $NN(\\mathbf{x})$ becomes an identity mapping of the original data. For example, when $\\mathbf{m}=0$, $NN(\\mathbf{x}) = \\mathbf{x}$ minimizes the loss function value, which is $0$. To make $NN(\\mathbf{x})$ uninformative, they added a loss term $\\Vert NN(\\mathbf{x})\\Vert$, using zero as the prior. The objective function is as follows: $$ \\argmin_{\\mathbf{m}, \\Theta \\in NN} \\lambda_{1} \\Vert \\mathbf{m}\\Vert_{1} + \\lambda_{2} \\Vert NN(\\mathbf{x})\\Vert_{1} + \\mathcal{L}(f(\\mathbf{x}), f(\\Phi(\\mathbf{x}, \\mathbf{m}))) $$they decompose the objective function as follows:\n$\\Vert \\mathbf{m}\\Vert_{1}$ induces $\\Phi(\\mathbf{x})$ to be closed to $NN(\\mathbf{x})$ $\\Vert\\Phi(\\mathbf{x})\\Vert_{1}$ induces $\\Phi(\\mathbf{x})$ to be close $\\mathbf{0}$ (uninformative) $\\mathcal{L}$ induces $f(\\Phi(\\mathbf{x}, \\mathbf{m}))$ to be close to $f(\\mathbf{x})$ (informative) It is worth mentioning that, when applying the ‘deletion game’, this paper considers the $-\\mathcal{L}(f(\\mathbf{x}), f(\\Phi(\\mathbf{x}, \\mathbf{m})))$ objective function difficult to optimize because making $f(\\Phi(\\mathbf{x}, \\mathbf{m}))$ distant from $f(\\mathbf{x})$ does not specify where the distant point should be. Therefore, they use $-\\mathcal{L}(f(\\mathbf{0}), f(\\Phi(\\mathbf{x}, \\mathbf{m})))$ instead of the original objective function.\nReferences Enguehard, J. (2023, July). Learning perturbations to explain time series predictions. In International Conference on Machine Learning (pp. 9329-9342). PMLR.\n","wordCount":"299","inLanguage":"en","datePublished":"2024-07-07T15:00:05+08:00","dateModified":"2024-07-07T15:00:05+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://lif323.github.io/posts/post-14/note-learningperturbations-2023/"},"publisher":{"@type":"Organization","name":"lif323","logo":{"@type":"ImageObject","url":"https://lif323.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://lif323.github.io/ accesskey=h title="lif323 (Alt + H)">lif323</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">Note Learning Perturbations ICML 2023</h1><div class=post-meta><span title='2024-07-07 15:00:05 +0800 +0800'>July 7, 2024</span></div></header><div class=post-content><p>This paper improves existing methods that provide explanations using trainable masks.
Inspired by methods for static data, the current approach uses fixed perturbations. However, this paper argues that this approach may not be suitable for time series data.
In this paper, their method not only has a trainable mask but also trainable perturbations.</p><p>Existing methods using fixed perturbations can be expressed as follows:</p>$$
\Phi(\mathbf{x}, \mathbf{m}) = \mathbf{m} \times \mathbf{x} + (1 - \mathbf{m}) \times g(\mathbf{x}),
$$<p>where $g(\mathbf{x})$ is a function of the input. A possible definition is $g(\mathbf{x}) = \frac{1}{W}\sum_{t'=t-W}^{t}x_{t'}$.</p><p>They propose to replace these fixed functions with a neural network (NN) and train it with the mask. Their perturbation is defined as:</p>$$
\Phi(\mathbf{x}, \mathbf{m}) = \mathbf{m} \times \mathbf{x} + (1 - \mathbf{m}) \times NN(\mathbf{x})
$$<p>In extreme cases, $NN(\mathbf{x})$ becomes an identity mapping of the original data. For example, when $\mathbf{m}=0$, $NN(\mathbf{x}) = \mathbf{x}$ minimizes the loss function value, which is $0$.
To make $NN(\mathbf{x})$ uninformative, they added a loss term $\Vert NN(\mathbf{x})\Vert$, using zero as the prior. The objective function is as follows:</p>$$
\argmin_{\mathbf{m}, \Theta \in NN} \lambda_{1} \Vert \mathbf{m}\Vert_{1} + \lambda_{2} \Vert NN(\mathbf{x})\Vert_{1} + \mathcal{L}(f(\mathbf{x}), f(\Phi(\mathbf{x}, \mathbf{m})))
$$<p>they decompose the objective function as follows:</p><ul><li>$\Vert \mathbf{m}\Vert_{1}$ induces $\Phi(\mathbf{x})$ to be closed to $NN(\mathbf{x})$</li><li>$\Vert\Phi(\mathbf{x})\Vert_{1}$ induces $\Phi(\mathbf{x})$ to be close $\mathbf{0}$ (uninformative)</li><li>$\mathcal{L}$ induces $f(\Phi(\mathbf{x}, \mathbf{m}))$ to be close to $f(\mathbf{x})$ (informative)</li></ul><p>It is worth mentioning that, when applying the &lsquo;deletion game&rsquo;, this paper considers the $-\mathcal{L}(f(\mathbf{x}), f(\Phi(\mathbf{x}, \mathbf{m})))$ objective function difficult to optimize because making $f(\Phi(\mathbf{x}, \mathbf{m}))$ distant from $f(\mathbf{x})$ does not specify where the distant point should be. Therefore, they use $-\mathcal{L}(f(\mathbf{0}), f(\Phi(\mathbf{x}, \mathbf{m})))$ instead of the original objective function.</p><h1 id=references>References<a hidden class=anchor aria-hidden=true href=#references>#</a></h1><p>Enguehard, J. (2023, July). Learning perturbations to explain time series predictions. In International Conference on Machine Learning (pp. 9329-9342). PMLR.</p></div><footer class=post-footer><ul class=post-tags></ul></footer><script src=https://giscus.app/client.js data-repo=lif323/lif323.github.io data-repo-id=R_kgDOLtjKFA data-category=Announcements data-category-id=DIC_kwDOLtjKFM4Ce08J data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=light data-lang=en crossorigin=anonymous async></script></article></main><footer class=footer><span>&copy; 2024 <a href=https://lif323.github.io/>lif323</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>
<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Notes on the Paper NeurIPS 2023 Evaluating Post Hoc Explanations for Graph Neural Networks via Robustness Analysis | My New Hugo Site</title>
<meta name=keywords content><meta name=description content="This paper focuses on the performance of evaluation methods of Post-hoc Explanations. Current prevailing evalution methods mainly inlcudes two types: Feature Removal methods and Generation-based methods.
This paper hones in on the evaluation of the effectiveness of Post-hoc Explanation evaluation methods. Predominantly, current methodologies fall into two primary classifications: Feature Removal and Generation-based approaches.
Feature Removal operates on the principle of excising salient features identified through explanation mechanisms. The merit of such explanations is quantified by the variance in the model&rsquo;s output pre and post-feature extrication."><meta name=author content><link rel=canonical href=https://lif323.github.io/posts/notes-on-the-paper-neurips-2023-evaluating-post-hoc-explanations-for-graph-neural-networks-via-robustness-analysis/><link crossorigin=anonymous href=/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z+V9+cO1A=" rel="preload stylesheet" as=style><link rel=icon href=https://lif323.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://lif323.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://lif323.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://lif323.github.io/apple-touch-icon.png><link rel=mask-icon href=https://lif323.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://lif323.github.io/posts/notes-on-the-paper-neurips-2023-evaluating-post-hoc-explanations-for-graph-neural-networks-via-robustness-analysis/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="Notes on the Paper NeurIPS 2023 Evaluating Post Hoc Explanations for Graph Neural Networks via Robustness Analysis"><meta property="og:description" content="This paper focuses on the performance of evaluation methods of Post-hoc Explanations. Current prevailing evalution methods mainly inlcudes two types: Feature Removal methods and Generation-based methods.
This paper hones in on the evaluation of the effectiveness of Post-hoc Explanation evaluation methods. Predominantly, current methodologies fall into two primary classifications: Feature Removal and Generation-based approaches.
Feature Removal operates on the principle of excising salient features identified through explanation mechanisms. The merit of such explanations is quantified by the variance in the model&rsquo;s output pre and post-feature extrication."><meta property="og:type" content="article"><meta property="og:url" content="https://lif323.github.io/posts/notes-on-the-paper-neurips-2023-evaluating-post-hoc-explanations-for-graph-neural-networks-via-robustness-analysis/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-04-13T12:45:24+08:00"><meta property="article:modified_time" content="2024-04-13T12:45:24+08:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Notes on the Paper NeurIPS 2023 Evaluating Post Hoc Explanations for Graph Neural Networks via Robustness Analysis"><meta name=twitter:description content="This paper focuses on the performance of evaluation methods of Post-hoc Explanations. Current prevailing evalution methods mainly inlcudes two types: Feature Removal methods and Generation-based methods.
This paper hones in on the evaluation of the effectiveness of Post-hoc Explanation evaluation methods. Predominantly, current methodologies fall into two primary classifications: Feature Removal and Generation-based approaches.
Feature Removal operates on the principle of excising salient features identified through explanation mechanisms. The merit of such explanations is quantified by the variance in the model&rsquo;s output pre and post-feature extrication."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://lif323.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Notes on the Paper NeurIPS 2023 Evaluating Post Hoc Explanations for Graph Neural Networks via Robustness Analysis","item":"https://lif323.github.io/posts/notes-on-the-paper-neurips-2023-evaluating-post-hoc-explanations-for-graph-neural-networks-via-robustness-analysis/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Notes on the Paper NeurIPS 2023 Evaluating Post Hoc Explanations for Graph Neural Networks via Robustness Analysis","name":"Notes on the Paper NeurIPS 2023 Evaluating Post Hoc Explanations for Graph Neural Networks via Robustness Analysis","description":"This paper focuses on the performance of evaluation methods of Post-hoc Explanations. Current prevailing evalution methods mainly inlcudes two types: Feature Removal methods and Generation-based methods.\nThis paper hones in on the evaluation of the effectiveness of Post-hoc Explanation evaluation methods. Predominantly, current methodologies fall into two primary classifications: Feature Removal and Generation-based approaches.\nFeature Removal operates on the principle of excising salient features identified through explanation mechanisms. The merit of such explanations is quantified by the variance in the model\u0026rsquo;s output pre and post-feature extrication.","keywords":[],"articleBody":"This paper focuses on the performance of evaluation methods of Post-hoc Explanations. Current prevailing evalution methods mainly inlcudes two types: Feature Removal methods and Generation-based methods.\nThis paper hones in on the evaluation of the effectiveness of Post-hoc Explanation evaluation methods. Predominantly, current methodologies fall into two primary classifications: Feature Removal and Generation-based approaches.\nFeature Removal operates on the principle of excising salient features identified through explanation mechanisms. The merit of such explanations is quantified by the variance in the model’s output pre and post-feature extrication. The larger the resultant decrement in model performance, which intimates the importance of the deleted features to the model’s functionality, the more adept the explanation method is deemed.\nHowever, the reliability of Feature Removal metrics is often compromised by the out-of-distribution problem. To address this, Generation-based metrics have been introduced. These metrics utilize a generative model to craft new data instances that inherently lack the pivotal features, rather than eliminating them from existing instances. Nonetheless, this approach is not without its drawbacks, as generative models are prone to incorporating and perpetuating inherent data biases in these newly created instances.\nTaking into account the aforementioned factors, this paper introduces a novel evaluation framework termed OAR (Out-of-Distribution-resistant Adversarial Robustness), designed to evaluate explanations with enhanced reliability.\nFirstly, they define the quality of explanation $E$ as the difficulty of reversing the prediction by perturbing features not belonging to $E$. $$ \\begin{equation} \\theta = \\mathbb{E}{F{-E}}\\left(f(F_{-E})_{c} - y_c\\right) \\end{equation} $$ where $F$ is the set of all features.\nSecond, the concept of reconstruction loss is employed as a metric to ascertain the extent of a sample’s deviation from its original distribution. By calculating the weighted average of the outputs from the generated instances, one can gauge the quality of the explanation. A smaller discrepancy between this average and the original output reflects a higher fidelity in the explanatory process.\n","wordCount":"310","inLanguage":"en","datePublished":"2024-04-13T12:45:24+08:00","dateModified":"2024-04-13T12:45:24+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://lif323.github.io/posts/notes-on-the-paper-neurips-2023-evaluating-post-hoc-explanations-for-graph-neural-networks-via-robustness-analysis/"},"publisher":{"@type":"Organization","name":"My New Hugo Site","logo":{"@type":"ImageObject","url":"https://lif323.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://lif323.github.io/ accesskey=h title="My New Hugo Site (Alt + H)">My New Hugo Site</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">Notes on the Paper NeurIPS 2023 Evaluating Post Hoc Explanations for Graph Neural Networks via Robustness Analysis</h1><div class=post-meta><span title='2024-04-13 12:45:24 +0800 +0800'>April 13, 2024</span></div></header><div class=post-content><p>This paper focuses on the performance of evaluation methods of Post-hoc Explanations. Current prevailing evalution methods mainly inlcudes two types: Feature Removal methods and Generation-based methods.</p><p>This paper hones in on the evaluation of the effectiveness of Post-hoc Explanation evaluation methods. Predominantly, current methodologies fall into two primary classifications: Feature Removal and Generation-based approaches.</p><p>Feature Removal operates on the principle of excising salient features identified through explanation mechanisms. The merit of such explanations is quantified by the variance in the model&rsquo;s output pre and post-feature extrication. The larger the resultant decrement in model performance, which intimates the importance of the deleted features to the model&rsquo;s functionality, the more adept the explanation method is deemed.</p><p>However, the reliability of Feature Removal metrics is often compromised by the out-of-distribution problem. To address this, Generation-based metrics have been introduced. These metrics utilize a generative model to craft new data instances that inherently lack the pivotal features, rather than eliminating them from existing instances. Nonetheless, this approach is not without its drawbacks, as generative models are prone to incorporating and perpetuating inherent data biases in these newly created instances.</p><p>Taking into account the aforementioned factors, this paper introduces a novel evaluation framework termed OAR (Out-of-Distribution-resistant Adversarial Robustness), designed to evaluate explanations with enhanced reliability.</p><p>Firstly, <strong>they define the quality of explanation $E$ as the difficulty of reversing the prediction by perturbing features not belonging to $E$</strong>.
$$
\begin{equation}
\theta = \mathbb{E}<em>{F</em>{-E}}\left(f(F_{-E})_{c} - y_c\right)
\end{equation}
$$
where $F$ is the set of all features.</p><p>Second, the concept of <strong>reconstruction loss</strong> is employed as a metric to ascertain the extent of a sample&rsquo;s deviation from its original distribution. By calculating the weighted average of the outputs from the generated instances, one can gauge the quality of the explanation. A smaller discrepancy between this average and the original output reflects a higher fidelity in the explanatory process.</p></div><footer class=post-footer><ul class=post-tags></ul></footer></article></main><footer class=footer><span>&copy; 2024 <a href=https://lif323.github.io/>My New Hugo Site</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>
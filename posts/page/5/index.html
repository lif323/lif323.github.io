<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="noindex, nofollow">
<title>Posts | lif323</title>
<meta name="keywords" content="">
<meta name="description" content="Posts - lif323">
<meta name="author" content="">
<link rel="canonical" href="http://localhost:1313/posts/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.1d23bc8761bb8a516d01801663a24eeedbf97720019a7ddc0fc9ff29a2a8730d.css" integrity="sha256-HSO8h2G7ilFtAYAWY6JO7tv5dyABmn3cD8n/KaKocw0=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:1313/apple-touch-icon.png">
<link rel="mask-icon" href="http://localhost:1313/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" type="application/rss+xml" href="http://localhost:1313/posts/index.xml">
<link rel="alternate" hreflang="en" href="http://localhost:1313/posts/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>




<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" integrity="sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js" integrity="sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"></script>
<script>
  document.addEventListener("DOMContentLoaded", function() {
    renderMathInElement(document.body, {
      delimiters: [
        {left: '\\[', right: '\\]', display: true},   
        {left: '$$', right: '$$', display: true},     
        {left: '$', right: '$', display: false},  
      ],
      throwOnError : false
    });
  });
</script>


</head>

<body class="list" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/" accesskey="h" title="lif323 (Alt + H)">lif323</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
        </ul>
    </nav>
</header>
<main class="main"> 
<header class="page-header">
  <h1>
    Posts
  </h1>
</header>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Note on MeaningfulPerturbation ICCV 2017
    </h2>
  </header>
  <div class="entry-content">
    <p>As far as I know, this paper is the first to propose providing explanations for black-box models by learning a mask. Additionally, this paper presents an interesting perspective, which views explaining black-box models as a form of meta-learning. Specifically, an explanation is a rule that predicts the block-box model’s output for a given input.
A significant advantage of formulating explanations as meta learning is that the fidelity of the explanations can be measured as prediction accuracy.
...</p>
  </div>
  <footer class="entry-footer"><span title='2024-06-18 22:07:07 +0800 CST'>June 18, 2024</span></footer>
  <a class="entry-link" aria-label="post link to Note on MeaningfulPerturbation ICCV 2017" href="http://localhost:1313/posts/post-7/note-on-meaningfulperturbation-iccv-2017/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Note on ConceptBottleneckModels ICML 2020
    </h2>
  </header>
  <div class="entry-content">
    <p>In this paper, they systematically study different ways of learning concept bottleneck models. Let $L_{c_j}$ be a loss function that measures the discrepancy between the predicted and true j-th concept, and let $L_Y$ measure the discrepancy between predicted and true targets. They consider the following ways to learn a concept bottleneck model $(\hat{f}, \hat{g})$:
The independent bottleneck learns $\hat{f}$ and $\hat{g}$ independently: $\hat{f} = \argmin_{f}\sum_{i}L_{Y}(f(c^{i}); y^i)$, and $\hat{g} = \argmin_{g}\sum_{i,j}L_{C_j}(g_j(x^i);c_j^i)$. While $\hat{f}$ is trained using the true $c$, at test time it still takes $\hat{g}(x)$ as input.
...</p>
  </div>
  <footer class="entry-footer"><span title='2024-06-14 21:13:21 +0800 CST'>June 14, 2024</span></footer>
  <a class="entry-link" aria-label="post link to Note on ConceptBottleneckModels ICML 2020" href="http://localhost:1313/posts/post-6/note-on-conceptbottleneckmodels-icml-2020/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Note on SaliencyGuidedTraining NeurIPS 2021
    </h2>
  </header>
  <div class="entry-content">
    <p>This paper proposes a saliency-guided training procedure aimed at reducing noisy gradients, which can lead to unfaithful feature attributions, while maintaining the predictive performance of the model.
During saliency-guided training, for every input $X$, they create a new input $\tilde{X}$ by masking the features with low gradient values as follows: $$ \tilde{X} = M_{k}(S(\nabla_{X}f_{\theta}(X), X), $$ where $S(\cdot)$ is a sorting function and $M(\cdot)$ replaces the bottom $k$ elements with a mask distribution based on the order provided by $S(\cdot)$.
...</p>
  </div>
  <footer class="entry-footer"><span title='2024-06-11 16:08:08 +0800 CST'>June 11, 2024</span></footer>
  <a class="entry-link" aria-label="post link to Note on SaliencyGuidedTraining NeurIPS 2021" href="http://localhost:1313/posts/post-5/note-on-saliencyguidedtraining-neurips-2021/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Note on DynaMask ICML 2021
    </h2>
  </header>
  <div class="entry-content">
    <p> This paper is among the earliest works to learn a mask to measure the importance of each feature. Assuming a mask $M$, where $M_{t,i} \in [0, 1] $. When $M_{t, i} = 0$, this feature is irrelevant for black-box prediction. Conversely, when $M_{t, i}=1$, this feature is important for black-box prediction. The input $x$ is perturbed based on $M_{t, i}$. A simple perturbation method is as follows: ...</p>
  </div>
  <footer class="entry-footer"><span title='2024-06-07 22:36:34 +0800 CST'>June 7, 2024</span></footer>
  <a class="entry-link" aria-label="post link to Note on DynaMask ICML 2021" href="http://localhost:1313/posts/post-4/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Note on GSAT ICML 2022
    </h2>
  </header>
  <div class="entry-content">
    <p> This paper introduces GSAT methods for generating explanations in graph learning. GSAT is composed of the following parts:
$G = (A, X)$ $A$ is the adjacency matrix and $X$ is the node attributes. Let $V$ and $E$ denote the node set and the edge set.
Firstly, the extractor $g_{\phi}$ encodes the input graph $G$ via a GNN into a set of node representations $(h_u | u \in X)$. For any two nodes $v$ and $u$, an MLP layer maps the concatenation of their node representations to the probability $p_{u, v} \in [0, 1]$ of an edge existing between that corresponding pair of nodes.
...</p>
  </div>
  <footer class="entry-footer"><span title='2024-05-30 17:40:58 +0800 CST'>May 30, 2024</span></footer>
  <a class="entry-link" aria-label="post link to Note on GSAT ICML 2022" href="http://localhost:1313/posts/post-3/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Gumbel Softmax
    </h2>
  </header>
  <div class="entry-content">
    <p>What is Gumbel-softmax? Gumbel-softmax is an efficient tool to sample from a categorical distribution.
Let $z$ be a categorical variable with class probabilities $\pi_1$, $\pi_2$, $\cdots$, $\pi_k$.
Before introducing the Gumbel softmax, we first present the Gumbel-Max trick. The Gumbel-Max trick is used to sample $z$ from a categorical distribution with class probabilities $\pi$: $$ z = \text{one\_hot}(\argmax_{i}\left[g_i &#43; log \pi_i\right]) $$ where $g_1$, $\cdots$, $g_k$ are i.i.d samples drawn from Gumbel(0, 1). The Gumbel(0, 1) distribution can be sampled by drawing $u \sim \text{Uniform}(0, 1)$ and computing $g = - \log (- \log (u))$.
...</p>
  </div>
  <footer class="entry-footer"><span title='2024-04-18 11:24:57 +0800 CST'>April 18, 2024</span></footer>
  <a class="entry-link" aria-label="post link to Gumbel Softmax" href="http://localhost:1313/posts/post-2/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Notes on the Paper NeurIPS 2023 Evaluating Post Hoc Explanations for Graph Neural Networks via Robustness Analysis
    </h2>
  </header>
  <div class="entry-content">
    <p>This paper focuses on the performance of evaluation methods of Post-hoc Explanations. Current prevailing evalution methods mainly inlcudes two types: Feature Removal methods and Generation-based methods.
This paper hones in on the evaluation of the effectiveness of Post-hoc Explanation evaluation methods. Predominantly, current methodologies fall into two primary classifications: Feature Removal and Generation-based approaches.
Feature Removal operates on the principle of excising salient features identified through explanation mechanisms. The merit of such explanations is quantified by the variance in the model’s output pre and post-feature extrication. The larger the resultant decrement in model performance, which intimates the importance of the deleted features to the model’s functionality, the more adept the explanation method is deemed.
...</p>
  </div>
  <footer class="entry-footer"><span title='2024-04-13 12:45:24 +0800 CST'>April 13, 2024</span></footer>
  <a class="entry-link" aria-label="post link to Notes on the Paper NeurIPS 2023 Evaluating Post Hoc Explanations for Graph Neural Networks via Robustness Analysis" href="http://localhost:1313/posts/post-1/notes-on-the-paper-neurips-2023-evaluating-post-hoc-explanations-for-graph-neural-networks-via-robustness-analysis/"></a>
</article>
<footer class="page-footer">
  <nav class="pagination">
    <a class="prev" href="http://localhost:1313/posts/page/4/">
      «&nbsp;Prev&nbsp;
    </a>
  </nav>
</footer>
    </main>
    
<footer class="footer">
    <span>&copy; 2025 <a href="http://localhost:1313/">lif323</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>

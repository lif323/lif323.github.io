<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Note on NeurIPS 2021 Out-of-Distribution Problem and Search Methods for Feature Importance | lif323</title>
<meta name=keywords content><meta name=description content="The main contributions of this paper are twofold:(1) investigating the Out-of-Distribution (OOD) problem in counterfactual inputs, and (2) proposing a Parallel Local Search (PLS) method for generating explanations.
Out-of-Distribution Problem
The possible causes of the OOD problem in FI explanations are shown in the following figure.


Even on in-distribution data, neural networks are sensitive to random parameter initialization, data ordering, and hyperparameters.
Therefore, neural networks are also influenced by these factors when processing OOD data."><meta name=author content><link rel=canonical href=https://lif323.github.io/posts/post-41/><link crossorigin=anonymous href=/assets/css/stylesheet.1d23bc8761bb8a516d01801663a24eeedbf97720019a7ddc0fc9ff29a2a8730d.css integrity="sha256-HSO8h2G7ilFtAYAWY6JO7tv5dyABmn3cD8n/KaKocw0=" rel="preload stylesheet" as=style><link rel=icon href=https://lif323.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://lif323.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://lif323.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://lif323.github.io/apple-touch-icon.png><link rel=mask-icon href=https://lif323.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://lif323.github.io/posts/post-41/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"\\[",right:"\\]",display:!0},{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],throwOnError:!1})})</script><meta property="og:title" content="Note on NeurIPS 2021 Out-of-Distribution Problem and Search Methods for Feature Importance"><meta property="og:description" content="The main contributions of this paper are twofold:(1) investigating the Out-of-Distribution (OOD) problem in counterfactual inputs, and (2) proposing a Parallel Local Search (PLS) method for generating explanations.
Out-of-Distribution Problem
The possible causes of the OOD problem in FI explanations are shown in the following figure.


Even on in-distribution data, neural networks are sensitive to random parameter initialization, data ordering, and hyperparameters.
Therefore, neural networks are also influenced by these factors when processing OOD data."><meta property="og:type" content="article"><meta property="og:url" content="https://lif323.github.io/posts/post-41/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-12-19T16:31:26+08:00"><meta property="article:modified_time" content="2024-12-19T16:31:26+08:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Note on NeurIPS 2021 Out-of-Distribution Problem and Search Methods for Feature Importance"><meta name=twitter:description content="The main contributions of this paper are twofold:(1) investigating the Out-of-Distribution (OOD) problem in counterfactual inputs, and (2) proposing a Parallel Local Search (PLS) method for generating explanations.
Out-of-Distribution Problem
The possible causes of the OOD problem in FI explanations are shown in the following figure.


Even on in-distribution data, neural networks are sensitive to random parameter initialization, data ordering, and hyperparameters.
Therefore, neural networks are also influenced by these factors when processing OOD data."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://lif323.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Note on NeurIPS 2021 Out-of-Distribution Problem and Search Methods for Feature Importance","item":"https://lif323.github.io/posts/post-41/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Note on NeurIPS 2021 Out-of-Distribution Problem and Search Methods for Feature Importance","name":"Note on NeurIPS 2021 Out-of-Distribution Problem and Search Methods for Feature Importance","description":"The main contributions of this paper are twofold:(1) investigating the Out-of-Distribution (OOD) problem in counterfactual inputs, and (2) proposing a Parallel Local Search (PLS) method for generating explanations.\nOut-of-Distribution Problem The possible causes of the OOD problem in FI explanations are shown in the following figure. Even on in-distribution data, neural networks are sensitive to random parameter initialization, data ordering, and hyperparameters. Therefore, neural networks are also influenced by these factors when processing OOD data.\n","keywords":[],"articleBody":"The main contributions of this paper are twofold:(1) investigating the Out-of-Distribution (OOD) problem in counterfactual inputs, and (2) proposing a Parallel Local Search (PLS) method for generating explanations.\nOut-of-Distribution Problem The possible causes of the OOD problem in FI explanations are shown in the following figure. Even on in-distribution data, neural networks are sensitive to random parameter initialization, data ordering, and hyperparameters. Therefore, neural networks are also influenced by these factors when processing OOD data.\nTo address the OOD problem, they propose Counterfactual Training to align the training and testing distributions. The core step of Counterfactual Training involves training a neural network using random explanations that remove most input tokens.\nEvaluating OOD performance for different Replace functions Robustness is measured by model accuracy, and the evaluation steps are as follows:\nEvaluate five different Replace functions on the same explanation. Compute the accuracy change for each removal proportion of features. For each removal proportion of features, the smaller the accuracy change, the better the Replace function performs in addressing the OOD problem. Result (1) The Attention Mask and Mask Token functions are the two most effective methods. (2) Counterfactual training mitigates the OOD problem for counterfactual inputs.\nSearch methods for explanation They propose a novel search method, Parallel Local Search (PLS), to explain feature importance.\nReferences Hase, Peter, Harry Xie, and Mohit Bansal. “The out-of-distribution problem in explainability and search methods for feature importance explanations.” Advances in neural information processing systems 34 (2021): 3650-3666.\n","wordCount":"243","inLanguage":"en","datePublished":"2024-12-19T16:31:26+08:00","dateModified":"2024-12-19T16:31:26+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://lif323.github.io/posts/post-41/"},"publisher":{"@type":"Organization","name":"lif323","logo":{"@type":"ImageObject","url":"https://lif323.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://lif323.github.io/ accesskey=h title="lif323 (Alt + H)">lif323</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">Note on NeurIPS 2021 Out-of-Distribution Problem and Search Methods for Feature Importance</h1><div class=post-meta><span title='2024-12-19 16:31:26 +0800 +0800'>December 19, 2024</span></div></header><div class=post-content><p>The main contributions of this paper are twofold:(1) investigating the Out-of-Distribution (OOD) problem in counterfactual inputs, and (2) proposing a Parallel Local Search (PLS) method for generating explanations.</p><h1 id=out-of-distribution-problem>Out-of-Distribution Problem<a hidden class=anchor aria-hidden=true href=#out-of-distribution-problem>#</a></h1><p>The possible causes of the OOD problem in FI explanations are shown in the following figure.
<img loading=lazy src=image.png alt="alt text">
Even on in-distribution data, neural networks are sensitive to random parameter initialization, data ordering, and hyperparameters.
Therefore, neural networks are also influenced by these factors when processing OOD data.</p><p>To address the OOD problem, they propose Counterfactual Training to align the training and testing distributions. The core step of Counterfactual Training involves training a neural network using random explanations that remove most input tokens.</p><h2 id=evaluating-ood-performance-for-different-replace-functions>Evaluating OOD performance for different Replace functions<a hidden class=anchor aria-hidden=true href=#evaluating-ood-performance-for-different-replace-functions>#</a></h2><p>Robustness is measured by model accuracy, and the evaluation steps are as follows:</p><ul><li>Evaluate five different Replace functions on the same explanation.</li><li>Compute the accuracy change for each removal proportion of features.</li><li>For each removal proportion of features, the smaller the accuracy change, the better the Replace function performs in addressing the OOD problem.</li></ul><h2 id=result>Result<a hidden class=anchor aria-hidden=true href=#result>#</a></h2><p><img loading=lazy src=image-1.png alt="alt text">
(1) The Attention Mask and Mask Token functions are the two most effective methods.
(2) Counterfactual training mitigates the OOD problem for counterfactual inputs.</p><h1 id=search-methods-for-explanation>Search methods for explanation<a hidden class=anchor aria-hidden=true href=#search-methods-for-explanation>#</a></h1><p>They propose a novel search method, Parallel Local Search (PLS), to explain feature importance.</p><h1 id=references>References<a hidden class=anchor aria-hidden=true href=#references>#</a></h1><p>Hase, Peter, Harry Xie, and Mohit Bansal. &ldquo;The out-of-distribution problem in explainability and search methods for feature importance explanations.&rdquo; Advances in neural information processing systems 34 (2021): 3650-3666.</p></div><footer class=post-footer><ul class=post-tags></ul></footer><script src=https://giscus.app/client.js data-repo=lif323/lif323.github.io data-repo-id=R_kgDOLtjKFA data-category=Announcements data-category-id=DIC_kwDOLtjKFM4Ce08J data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=light data-lang=en crossorigin=anonymous async></script></article></main><footer class=footer><span>&copy; 2025 <a href=https://lif323.github.io/>lif323</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>
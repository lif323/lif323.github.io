<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Posts | lif323</title>
<meta name=keywords content><meta name=description content="Posts - lif323"><meta name=author content><link rel=canonical href=https://lif323.github.io/posts/><link crossorigin=anonymous href=/assets/css/stylesheet.1d23bc8761bb8a516d01801663a24eeedbf97720019a7ddc0fc9ff29a2a8730d.css integrity="sha256-HSO8h2G7ilFtAYAWY6JO7tv5dyABmn3cD8n/KaKocw0=" rel="preload stylesheet" as=style><link rel=icon href=https://lif323.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://lif323.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://lif323.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://lif323.github.io/apple-touch-icon.png><link rel=mask-icon href=https://lif323.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://lif323.github.io/posts/index.xml><link rel=alternate hreflang=en href=https://lif323.github.io/posts/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"\\[",right:"\\]",display:!0},{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],throwOnError:!1})})</script><meta property="og:title" content="Posts"><meta property="og:description" content><meta property="og:type" content="website"><meta property="og:url" content="https://lif323.github.io/posts/"><meta name=twitter:card content="summary"><meta name=twitter:title content="Posts"><meta name=twitter:description content><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://lif323.github.io/posts/"}]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://lif323.github.io/ accesskey=h title="lif323 (Alt + H)">lif323</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu></ul></nav></header><main class=main><header class=page-header><h1>Posts</h1></header><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Note Learning Perturbation ICML 2023</h2></header><div class=entry-content><p>This work is an extension of DynaMask. In DynaMask, perturbations are local and fixed. However, time series data typically exhibit long-term dependencies, making it insufficient to determine the importance of a feature at a specific time point based solely on local information.
In DynaMask, the perturbation function is defined as follows: $$ \Phi(x) = m \cdot x + (1 - m) \cdot f(x) $$ where f(x) is a fixed function. A possible definition is $f(x_{t}) = \frac{1}{W} \sum_{t'=t- W}^{t} x_{t'}$....</p></div><footer class=entry-footer><span title='2024-08-12 21:55:53 +0800 +0800'>August 12, 2024</span></footer><a class=entry-link aria-label="post link to Note Learning Perturbation ICML 2023" href=https://lif323.github.io/posts/post-18/note-learning-perturbation-icml-2023/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Note Integrated Directional Gradients</h2></header><div class=entry-content><p>This paper proposes the Integrated Directional Gradients (IDG) to computing feature group attribution. One important thing is to find the family of meaningful feature subsets which is defined by the domain related methods, such as the constituency parse tree for NLP.
In IDG, the importance of a subset of features is the path integral of the directional gradient over the straight line path from the baseline $b$ to the input $x$....</p></div><footer class=entry-footer><span title='2024-08-05 16:07:54 +0800 +0800'>August 5, 2024</span></footer><a class=entry-link aria-label="post link to Note Integrated Directional Gradients" href=https://lif323.github.io/posts/post-17/note-integrated-directional-gradients/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Note Ranking Problems</h2></header><div class=entry-content><p>In machine learning, most problems are classified as Classification or Regression. However, this categorization is not always suitable for real-world problems. In some tasks, the classes are imbalanced but exhibit some weak order. In these cases, the loss functions for Classification and Regression do not perform well. This blog will apply the less commonly used margin ranking loss to address this issue.
Here is an example from the UCI Wine Quality Dataset from Cortez et al....</p></div><footer class=entry-footer><span title='2024-07-14 09:09:56 +0800 +0800'>July 14, 2024</span></footer><a class=entry-link aria-label="post link to Note Ranking Problems" href=https://lif323.github.io/posts/post-16/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Note Discretized Integrated Gradients EMNLP 2021</h2></header><div class=entry-content><p>This paper proposes the Discretized Integrated Gradients (DIG) method, which effectively applies the Integrated Gradients(IG) method to the word embedding space.
Integrated Gradient (IG) measures the importance of features by using the average of model gradients at interpolation points along a straight path in the input space.
However, in the word embedding space, due to its discrete nature, interpolation points may not accurately represent textual data. In particular cases, interpolation points could be outliers....</p></div><footer class=entry-footer><span title='2024-07-08 15:58:29 +0800 +0800'>July 8, 2024</span></footer><a class=entry-link aria-label="post link to Note Discretized Integrated Gradients EMNLP 2021" href=https://lif323.github.io/posts/post-15/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Note LearningPerturbations 2023</h2></header><div class=entry-content><p>This paper improves existing methods that provide explanations using trainable masks. Inspired by methods for static data, the current approach uses fixed perturbations. However, this paper argues that this approach may not be suitable for time series data. In this paper, their method not only has a trainable mask but also trainable perturbations.
Existing methods using fixed perturbations can be expressed as follows: $$ \Phi(\mathbf{x}, \mathbf{m}) = \mathbf{m} \times \mathbf{x} + (1 - \mathbf{m}) \times \mu(\mathbf{x}), $$ where $\mu(\mathbf{x})$ is a function of the input....</p></div><footer class=entry-footer><span title='2024-07-07 15:00:05 +0800 +0800'>July 7, 2024</span></footer><a class=entry-link aria-label="post link to Note LearningPerturbations 2023" href=https://lif323.github.io/posts/post-14/note-learningperturbations-2023/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>KL Divergence and Cross Entropy</h2></header><div class=entry-content><p>The defination of Cross-entropy is as follows: $$ H(P, Q) = - \sum_{x}p(x)\log Q(x) $$The KL divergence is defined as follows: $$ KL(P|Q) = \sum_{x}P(x)\log\frac{P(x)}{Q(x)} $$We first introduce the definition of information entropy: $$ S(v) = - \sum_{i}p(v_i)\log p(v_i), $$ where $p(v_i)$ represents the probability of state $v_i$. From the perspective of information theory, $S(v)$ is the information required to remove system uncertainty.
The formula for KL divergence can be further transformed into the following form: $$ KL(A|B) = \sum_{i}p_A(v_i)\log p_A(v_i) - p_A(v_i)\log p_B(v_i), $$ where the first term of the right hand side is the entropy of distribution $A$, the second term can be interpreted as the expectation of distribution $B$ in terms of $A$....</p></div><footer class=entry-footer><span title='2024-06-24 21:37:58 +0800 +0800'>June 24, 2024</span></footer><a class=entry-link aria-label="post link to KL Divergence and Cross Entropy" href=https://lif323.github.io/posts/post-12/kl-divergence-and-cross-entropy/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Note on RealTimeImageSaliency NeurIPS 2017</h2></header><div class=entry-content><p>This paper proposes a fast saliency deletion method that can be applied to any differentiable image classifier. Their method provides explanations for model output by learning a mask $M$, where each element in $M$ represents the importance of elements in the input. The perturbation method is defined as follows: $$ \Phi(X, M) = X \odot M + A \odot (1 - M), $$ where $X$ is the original input, and $A$ is a reference input, which is usually a highly blurred version of $X$....</p></div><footer class=entry-footer><span title='2024-06-24 15:59:28 +0800 +0800'>June 24, 2024</span></footer><a class=entry-link aria-label="post link to Note on RealTimeImageSaliency NeurIPS 2017" href=https://lif323.github.io/posts/post-11/note-on-realtimeimagesaliency-neurips-2017/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Note on Extremal Perturbation ICCV 2019</h2></header><div class=entry-content><p>This paper is an improvement on meaningful perturbation(2017 Interpretable explanations of black boxes by meaningful perturbation). They reformulate the optimization problem of meaningful perturbation as follows: $$ m_{\lambda, \beta} = \argmax_{m} \Phi(m \otimes x) - \lambda \|m\|_{1} - \beta \mathcal{S}(m). $$They believe that the meaning of the trade-off of this formulation is unclear. In particular, choosing different $\lambda$ and $\beta$ will result in different masks without a clear way of comparing them....</p></div><footer class=entry-footer><span title='2024-06-21 16:16:47 +0800 +0800'>June 21, 2024</span></footer><a class=entry-link aria-label="post link to Note on Extremal Perturbation ICCV 2019" href=https://lif323.github.io/posts/post-10/note-on-extremal-perturbation-iccv-2019/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Cross Entropy</h2></header><div class=entry-content><p>Cross-entropy is commonly used to quantify the difference between two probability distributions. In machine learning, its definition for one instance is as follows: $$ H(p, q) = - \sum_{c \in C} p(c)\log q(c) $$The ’true’ distribution is usually expressed in terms of a one-hot distribution.
Suppose that the true label of an instance is B. The one-hot distribution for this instance is:
Pr(Class A) Pr(Class B) Pr(Class C) 0.0 1.0 0....</p></div><footer class=entry-footer><span title='2024-06-20 15:57:12 +0800 +0800'>June 20, 2024</span></footer><a class=entry-link aria-label="post link to Cross Entropy" href=https://lif323.github.io/posts/post-8/cross_entropy/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Note on MeaningfulPerturbation ICCV 2017</h2></header><div class=entry-content><p>As far as I know, this paper is the first to propose providing explanations for black-box models by learning a mask. Additionally, this paper presents an interesting perspective, which views explaining black-box models as a form of meta-learning. Specifically, an explanation is a rule that predicts the block-box model’s output for a given input.
A significant advantage of formulating explanations as meta learning is that the fidelity of the explanations can be measured as prediction accuracy....</p></div><footer class=entry-footer><span title='2024-06-18 22:07:07 +0800 +0800'>June 18, 2024</span></footer><a class=entry-link aria-label="post link to Note on MeaningfulPerturbation ICCV 2017" href=https://lif323.github.io/posts/post-7/note-on-meaningfulperturbation-iccv-2017/></a></article><footer class=page-footer><nav class=pagination><a class=next href=https://lif323.github.io/posts/page/2/>Next&nbsp;&nbsp;»</a></nav></footer></main><footer class=footer><span>&copy; 2024 <a href=https://lif323.github.io/>lif323</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>
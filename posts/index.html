<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Posts | lif323</title>
<meta name=keywords content><meta name=description content="Posts - lif323"><meta name=author content><link rel=canonical href=https://lif323.github.io/posts/><link crossorigin=anonymous href=/assets/css/stylesheet.1d23bc8761bb8a516d01801663a24eeedbf97720019a7ddc0fc9ff29a2a8730d.css integrity="sha256-HSO8h2G7ilFtAYAWY6JO7tv5dyABmn3cD8n/KaKocw0=" rel="preload stylesheet" as=style><link rel=icon href=https://lif323.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://lif323.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://lif323.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://lif323.github.io/apple-touch-icon.png><link rel=mask-icon href=https://lif323.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://lif323.github.io/posts/index.xml><link rel=alternate hreflang=en href=https://lif323.github.io/posts/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"\\[",right:"\\]",display:!0},{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],throwOnError:!1})})</script><meta property="og:title" content="Posts"><meta property="og:description" content><meta property="og:type" content="website"><meta property="og:url" content="https://lif323.github.io/posts/"><meta name=twitter:card content="summary"><meta name=twitter:title content="Posts"><meta name=twitter:description content><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://lif323.github.io/posts/"}]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://lif323.github.io/ accesskey=h title="lif323 (Alt + H)">lif323</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu></ul></nav></header><main class=main><header class=page-header><h1>Posts</h1></header><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>MAE: Masked Autoencoder CVPR 2021</h2></header><div class=entry-content><p>This paper proposes a scalable self-supervised learning method-Masked Autoencoders (MAE) for computer vision. MAE reconstructs the missing pixels from randomly masked images. MAE has two key design elements.
Firstly, the encoder-decoder architecture is asymmetric. The encoder processes only the visible parts of the image, ignoring the masked pixels. However, the decoder’s input includes not only the encoded visiable pixels but also the masked tokens. Specifically, the masked tokens are shared, learnable vectors that represent the missing pixels to predicted. Notably, the decoder is lightweight.
...</p></div><footer class=entry-footer><span title='2024-09-18 10:38:12 +0800 +0800'>September 18, 2024</span></footer><a class=entry-link aria-label="post link to MAE: Masked Autoencoder CVPR 2021" href=https://lif323.github.io/posts/post-29/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Moco CVPR 2020</h2></header><div class=entry-content><p>This paper proposes a Momentum Contrast (MoCo) method for unsupervised visual representation learning. Unlike previous methods, MoCo treats contrastive learning as a dictionary loolup task. The framework of MoCo is outlined as follows: Moco trains the visual representation encoder by matching the encoder query $q$ with keys encoded in a dictionary. Notably, the encoder is optimized via backpropagation, while the momentum encoder is optimized using the momentum update. The momentum update is defined as follows: ...</p></div><footer class=entry-footer><span title='2024-09-16 17:03:35 +0800 +0800'>September 16, 2024</span></footer><a class=entry-link aria-label="post link to Moco CVPR 2020" href=https://lif323.github.io/posts/post-28/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>DiET NeurIPS 2023</h2></header><div class=entry-content><p>A major issue with post-hoc explainability is its inability to faithfully represent the model’s underlying decision-making process. This primarily arises from the fact that post-hoc methods typically generate explanations using perturbation techniques, which create perturbed instances by altering the features of an instance, potentially pushing them outside the original data distribution.
Two approaches can address this issue. One approach involving ensure that perturbed instances remain within the original data distribution, typically by leveraging generative models. The other approach requires the model’s predictions to remain unchanged when unimportant features in the instance are perturbed. This paper adopts the latter approach.
...</p></div><footer class=entry-footer><span title='2024-09-14 21:29:31 +0800 +0800'>September 14, 2024</span></footer><a class=entry-link aria-label="post link to DiET NeurIPS 2023" href=https://lif323.github.io/posts/post-27/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>RISE: Randomized Input Sampling for Explanation</h2></header><div class=entry-content><p>The key idea of RISE to measure the importance of an image region is to obscure or ‘perturb’ it and observe how much this affects the black box decision.
RISE Assume that $\mathbf{M}:\Lambda \rightarrow \{0, 1\}$ is a binary mask with distribution $\mathcal{D}$. They consider the confidence score of perturbed input as the random variable $f(\mathbf{I} \odot \mathbf{M})$. They define importance of pixel $\lambda$ as the expected score over all possible masks $\mathbf{M}$ over all possible masks $\mathbf{M}$ conditioned on the event that pixel $\lambda$ is observed, i.e. $\mathbf{M}({\lambda}) = 1$: ...</p></div><footer class=entry-footer><span title='2024-09-05 22:34:19 +0800 +0800'>September 5, 2024</span></footer><a class=entry-link aria-label="post link to RISE: Randomized Input Sampling for Explanation" href=https://lif323.github.io/posts/post-26/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Frequency masking</h2></header><div class=entry-content><p>This paper proposes a method called FreqRISE. Current apporaches assume that salient information resides in the time domain (the raw input space), they argue that this assumption is less reasonable and that salient information is more likely to reside in the frequency domain.
Traditional mask-based methods use a mask $\mathbf{M}$ to occlude features in the input space by performing element-wise multiplication: : $$ \hat{\mathbf{X}} = \mathbf{X} \odot \mathbf{M}. $$ Then, they observe the changes in the output of the model $f$. ...</p></div><footer class=entry-footer><span title='2024-09-05 16:37:03 +0800 +0800'>September 5, 2024</span></footer><a class=entry-link aria-label="post link to Frequency masking" href=https://lif323.github.io/posts/post-25/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Maximum Likelihood Estimation and KL Divergence</h2></header><div class=entry-content><p>The core idea of maximum likelihood estimation is to assume that we draw samples $\{x^1, x^2, \cdots, x^m\}$ from the data distribution $P_{\text{data}}(x)$ and calculate the probability $P_{\theta}(x^i)$ of observing each sample $x^i$. The objective is to find the parameters $\theta$ that maximize the likelihood of observing all the samples. The optimization objective is formulated as follows:
$$ \theta^{*} = \argmax_{\theta} \prod_{i=1}^{m} P_{\theta}(x^i) $$Now, we will explore the relationship between maximum likelihood estimation and KL divergence. ...</p></div><footer class=entry-footer><span title='2024-09-04 10:43:33 +0800 +0800'>September 4, 2024</span></footer><a class=entry-link aria-label="post link to Maximum Likelihood Estimation and KL Divergence" href=https://lif323.github.io/posts/post-24/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Note Integrated Directional Gradients</h2></header><div class=entry-content><p>This paper proposes the Integrated Directional Gradients (IDG) to computing feature group attribution. One important thing is to find the family of meaningful feature subsets which is defined by the domain related methods, such as the constituency parse tree for NLP.
In IDG, the importance of a subset of features is the path integral of the directional gradient over the straight line path from the baseline $b$ to the input $x$. The process of computing the importance $v(S)$ of a subset of features is defined as follows: Firstly, they compute the difference vector $z^S$: ...</p></div><footer class=entry-footer><span title='2024-08-05 16:07:54 +0800 +0800'>August 5, 2024</span></footer><a class=entry-link aria-label="post link to Note Integrated Directional Gradients" href=https://lif323.github.io/posts/post-17/note-integrated-directional-gradients/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Note Ranking Problems</h2></header><div class=entry-content><p>In machine learning, most problems are classified as Classification or Regression. However, this categorization is not always suitable for real-world problems. In some tasks, the classes are imbalanced but exhibit some weak order. In these cases, the loss functions for Classification and Regression do not perform well. This blog will apply the less commonly used margin ranking loss to address this issue.
Here is an example from the UCI Wine Quality Dataset from Cortez et al. Suppose we are a wine supplier and we find that a high review in some wine magazines increases the demand for a particular wine. Therefore, we want to predict the review score based on some measurable features of the wine. This way, we can increase the stock of the corresponding wine in advance, before the demand rises.
...</p></div><footer class=entry-footer><span title='2024-07-14 09:09:56 +0800 +0800'>July 14, 2024</span></footer><a class=entry-link aria-label="post link to Note Ranking Problems" href=https://lif323.github.io/posts/post-16/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Note Discretized Integrated Gradients EMNLP 2021</h2></header><div class=entry-content><p>This paper proposes the Discretized Integrated Gradients (DIG) method, which effectively applies the Integrated Gradients(IG) method to the word embedding space.
Integrated Gradient (IG) measures the importance of features by using the average of model gradients at interpolation points along a straight path in the input space.
However, in the word embedding space, due to its discrete nature, interpolation points may not accurately represent textual data. In particular cases, interpolation points could be outliers.
...</p></div><footer class=entry-footer><span title='2024-07-08 15:58:29 +0800 +0800'>July 8, 2024</span></footer><a class=entry-link aria-label="post link to Note Discretized Integrated Gradients EMNLP 2021" href=https://lif323.github.io/posts/post-15/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Note Learning Perturbations ICML 2023</h2></header><div class=entry-content><p>This paper improves existing methods that provide explanations using trainable masks. Inspired by methods for static data, the current approach uses fixed perturbations. However, this paper argues that this approach may not be suitable for time series data. In this paper, their method not only has a trainable mask but also trainable perturbations.
Existing methods using fixed perturbations can be expressed as follows: $$ \Phi(\mathbf{x}, \mathbf{m}) = \mathbf{m} \times \mathbf{x} + (1 - \mathbf{m}) \times g(\mathbf{x}), $$ where $g(\mathbf{x})$ is a function of the input. A possible definition is $g(\mathbf{x}) = \frac{1}{W}\sum_{t'=t-W}^{t}x_{t'}$.
...</p></div><footer class=entry-footer><span title='2024-07-07 15:00:05 +0800 +0800'>July 7, 2024</span></footer><a class=entry-link aria-label="post link to Note Learning Perturbations ICML 2023" href=https://lif323.github.io/posts/post-14/note-learningperturbations-2023/></a></article><footer class=page-footer><nav class=pagination><a class=next href=https://lif323.github.io/posts/page/2/>Next&nbsp;&nbsp;»</a></nav></footer></main><footer class=footer><span>&copy; 2024 <a href=https://lif323.github.io/>lif323</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>
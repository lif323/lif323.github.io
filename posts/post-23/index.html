<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Diffusion Models | lif323</title>
<meta name=keywords content><meta name=description content="$$
X_0 \rightarrow \cdots \rightarrow X_{t} \rightarrow \cdots \rightarrow X_{T}
$$$$
X_T \rightarrow \cdots \rightarrow X_{t} \rightarrow \cdots \rightarrow X_{0}
$$
$X_T$: noise
$X_0$: original sample
VAE vs. Diffusion model


In diffusion model, the process of adding noise is similar with encoder in VAE, except that it is not learnable. The process of denoise is similar with decoder in VAE.
Training in Diffusion model


$\mathbf{\epsilon}_{\theta}$ is a noise predictor. It take as input the noised image, and time step $t$ to predict the noise."><meta name=author content><link rel=canonical href=https://lif323.github.io/posts/post-23/><link crossorigin=anonymous href=/assets/css/stylesheet.1d23bc8761bb8a516d01801663a24eeedbf97720019a7ddc0fc9ff29a2a8730d.css integrity="sha256-HSO8h2G7ilFtAYAWY6JO7tv5dyABmn3cD8n/KaKocw0=" rel="preload stylesheet" as=style><link rel=icon href=https://lif323.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://lif323.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://lif323.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://lif323.github.io/apple-touch-icon.png><link rel=mask-icon href=https://lif323.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://lif323.github.io/posts/post-23/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"\\[",right:"\\]",display:!0},{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],throwOnError:!1})})</script><meta property="og:title" content="Diffusion Models"><meta property="og:description" content="$$
X_0 \rightarrow \cdots \rightarrow X_{t} \rightarrow \cdots \rightarrow X_{T}
$$$$
X_T \rightarrow \cdots \rightarrow X_{t} \rightarrow \cdots \rightarrow X_{0}
$$
$X_T$: noise
$X_0$: original sample
VAE vs. Diffusion model


In diffusion model, the process of adding noise is similar with encoder in VAE, except that it is not learnable. The process of denoise is similar with decoder in VAE.
Training in Diffusion model


$\mathbf{\epsilon}_{\theta}$ is a noise predictor. It take as input the noised image, and time step $t$ to predict the noise."><meta property="og:type" content="article"><meta property="og:url" content="https://lif323.github.io/posts/post-23/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-09-03T11:54:04+08:00"><meta property="article:modified_time" content="2024-09-03T11:54:04+08:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Diffusion Models"><meta name=twitter:description content="$$
X_0 \rightarrow \cdots \rightarrow X_{t} \rightarrow \cdots \rightarrow X_{T}
$$$$
X_T \rightarrow \cdots \rightarrow X_{t} \rightarrow \cdots \rightarrow X_{0}
$$
$X_T$: noise
$X_0$: original sample
VAE vs. Diffusion model


In diffusion model, the process of adding noise is similar with encoder in VAE, except that it is not learnable. The process of denoise is similar with decoder in VAE.
Training in Diffusion model


$\mathbf{\epsilon}_{\theta}$ is a noise predictor. It take as input the noised image, and time step $t$ to predict the noise."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://lif323.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Diffusion Models","item":"https://lif323.github.io/posts/post-23/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Diffusion Models","name":"Diffusion Models","description":"$$ X_0 \\rightarrow \\cdots \\rightarrow X_{t} \\rightarrow \\cdots \\rightarrow X_{T} $$$$ X_T \\rightarrow \\cdots \\rightarrow X_{t} \\rightarrow \\cdots \\rightarrow X_{0} $$ $X_T$: noise $X_0$: original sample\nVAE vs. Diffusion model In diffusion model, the process of adding noise is similar with encoder in VAE, except that it is not learnable. The process of denoise is similar with decoder in VAE.\nTraining in Diffusion model $\\mathbf{\\epsilon}_{\\theta}$ is a noise predictor. It take as input the noised image, and time step $t$ to predict the noise.\n","keywords":[],"articleBody":"$$ X_0 \\rightarrow \\cdots \\rightarrow X_{t} \\rightarrow \\cdots \\rightarrow X_{T} $$$$ X_T \\rightarrow \\cdots \\rightarrow X_{t} \\rightarrow \\cdots \\rightarrow X_{0} $$ $X_T$: noise $X_0$: original sample\nVAE vs. Diffusion model In diffusion model, the process of adding noise is similar with encoder in VAE, except that it is not learnable. The process of denoise is similar with decoder in VAE.\nTraining in Diffusion model $\\mathbf{\\epsilon}_{\\theta}$ is a noise predictor. It take as input the noised image, and time step $t$ to predict the noise.\nInference in Diffusion model Notably, after removing the noise, additional noise $\\mathbf{z}$ is added.\nForward Process The forward process is one where noise is gradually added to the original distribution of the image $x_0 \\sim q(x_0)$.\nThe distribution between adjacent time steps is given as follows, where $\\beta_t$ is a predefined parameter that increases gradually with each time step.\n$$ q(x_t| x_{t-1}) = \\mathcal{N}(x_t; \\sqrt{1 - \\beta_{t}}x_{t-1}, \\beta_{t}\\mathbf{I}) $$$$ \\begin{aligned} x_t = \\sqrt{1 - \\beta_t} x_{t-1} + \\sqrt{\\beta_t}\\epsilon_{t-1}, \\text{where } \\epsilon_t \\sim \\mathcal{N}(0, \\mathbf{I}) \\end{aligned} $$$$ \\begin{aligned} x_t \u0026= \\sqrt{\\alpha_t} x_{t-1} + \\sqrt{1 - \\alpha_t}\\epsilon_{t-1} \\\\ \u0026= \\sqrt{\\alpha_t} (\\sqrt{\\alpha_{t-1}} x_{t-2} + \\sqrt{1 - \\alpha_{t-1}}\\epsilon_{t-2}) + \\sqrt{1 - \\alpha_t}\\epsilon_{t-1} \\\\ \u0026= \\sqrt{\\alpha_{t}\\alpha_{t-1}} x_{t-2} + \\sqrt{\\alpha_{t}(1 - \\alpha_{t-1})} \\epsilon_{t-2} + \\sqrt{1 - \\alpha_{t}} \\epsilon_{t-1}\\\\ \\end{aligned} $$ Since the variance of $\\mathcal{N}_1 + \\mathcal{N}_2$ is $\\sigma_1 + \\sigma_2$, we have $\\sqrt{\\alpha_{t}(1 - \\alpha_{t-1})} \\epsilon_{t-2} + \\sqrt{1 - \\alpha_{t}} \\epsilon_{t-1} \\sim \\mathcal{N}(0, (1-\\alpha_t \\alpha_{t-1})\\mathbf{I})$.\n$$ \\begin{aligned} x_{t} \u0026= \\sqrt{\\alpha_{t}\\alpha_{t-1}} x_{t-2} + \\sqrt{1 - \\alpha_{t}\\alpha_{t-1}} \\epsilon\\\\ \u0026\\vdots\\\\ x_{t} \u0026= \\sqrt{\\bar{\\alpha}_{t}} x_{0} + \\sqrt{1 - \\bar{\\alpha}_{t}} \\epsilon \\quad \\bar{\\alpha}_{t} = \\prod_{s=1}^{t}\\alpha_{s} \\end{aligned} $$$$ q(x_t|x_0) = \\mathcal{N}(x_t; \\sqrt{\\bar{\\alpha}_{t}} x_{0}, (1 - \\bar{\\alpha}_{t}) \\mathbf{I}) $$Based on the above equation, we can conveniently obtain the sample at time step $t$.\nReverse Process $$ \\begin{aligned} q(x_{t-1}|x_{t}, x_0) \u0026= \\frac{q(x_{t-1}, x_{t}, x_0)}{q(x_{t}, x_0)} \\\\ \u0026=\\frac{q(x_t|x_{t-1}, x_0)q(x_{t-1}|x_0)q(x_0)}{q(x_{t}|x_0) q(x_0)} \\\\ \u0026=\\frac{q(x_t|x_{t-1}, x_0)q(x_{t-1}|x_0)}{q(x_{t}|x_0)} \\end{aligned} $$ where, $q(x_t|x_{t-1}, x_0) = q(x_t|x_{t-1})$ which is based on markov assumption.\n$$ \\begin{aligned} q(x_{t-1}|x_{t}, x_{0}) \u0026= \\frac{q(x_{t}|x_{t-1}, x_{0}) q(x_{t-1} | x_{0})}{q(x_{t}|x_{0})} \\\\ \u0026\\propto \\exp ( (- \\frac{(x_t - \\sqrt{1 - \\beta_{t}}x_{t-1})^2}{2\\beta_{t}}) + (- \\frac{(x_{t-1} - \\sqrt{\\bar{\\alpha}_{t-1}}x_{0})^2}{2(1 - \\bar{\\alpha}_{t-1})}) - (- \\frac{(x_{t} - \\sqrt{\\bar{\\alpha}_{t}}x_{0})^2}{2(1 - \\bar{\\alpha}_{t})}) )\\\\ \u0026\\propto \\exp \\left( -\\frac{1}{2}\\cdot ( (\\frac{\\alpha_{t}}{\\beta_{t}} + \\frac{1}{1 - \\bar{a}_{t-1}}) x^{2}_{t-1} + (\\frac{-2 \\sqrt{\\alpha_{t}} x_{t}}{\\beta_{t}} + \\frac{-2\\sqrt{\\bar{\\alpha}_{t-1}} x_{0}}{1 - \\bar{\\alpha}_{t-1}})x_{t-1} - C(x_t, x_0) ) \\right) \\end{aligned} $$$$ \\begin{aligned} a \u0026= \\frac{\\alpha_{t}}{\\beta_{t}} + \\frac{1}{1 - \\bar{a}_{t-1}} \\\\ b \u0026= \\frac{-2 \\sqrt{\\alpha_{t}} x_{t}}{\\beta_{t}} + \\frac{-2\\sqrt{\\bar{\\alpha}_{t-1}} x_{0}}{1 - \\bar{\\alpha}_{t-1}} \\\\ \\end{aligned} $$$$ \\begin{aligned} \\mu = - \\frac{b}{2a} = \\frac{\\sqrt{\\alpha_{t}}(1 - \\bar{\\alpha}_{t-1})}{1 - \\bar{\\alpha}_{t} } x_{t} + \\frac{(1 - \\alpha_{t}) \\sqrt{\\bar{\\alpha}_{t-1}}}{1 - \\bar{\\alpha}_{t}} x_{0} \\\\ \\end{aligned} $$$$ x_0 = \\frac{1}{\\sqrt{\\bar{\\alpha}_{t}}} (x_{t} - \\sqrt{1 - \\bar{\\alpha}_{t}} \\epsilon)$$$$ \\mu = \\frac{1}{\\sqrt{\\bar{\\alpha}_{t}}} (x_t - \\frac{1 - \\alpha_{t}}{\\sqrt{1 - \\bar{\\alpha}_{t}}} \\epsilon ) $$Since $\\Sigma$ is only related to $\\beta$, it is a constant.\n$$ q(x_{t-1}|x_t, x_0) \\propto \\mathcal{N}(x_{t-1}; \\underbrace{\\frac{\\sqrt \\alpha_t (1 - \\overline{a}_{t-1})x_t + \\sqrt{\\overline{\\alpha}_{t-1}} (1 - \\overline{a}_{t}) x_0 }{1 - \\overline{\\alpha}_t}}_{\\mu_{q}(x_t, x_0)}, \\underbrace{\\frac{(1 - \\alpha_t)(1 - \\overline{a}_{t-1})}{1 - \\overline{\\alpha}_{t}}I}_{\\Sigma_{q}(t)}) $$Loss function of DDM Aim of image generation Let $z$ be the latent space, then a neural network $G$ take $z$ as input and output a image $x$, they want the distribution of $x$ to be as close as with the real image generation.\n$$ \\theta^{*} = \\argmax_{\\theta}\\prod_{i=1}^{m}P_{\\theta}(x^i) $$$$ \\begin{aligned} \u0026 \\theta^*= \\arg \\max _\\theta \\prod_{i=1}^m P_\\theta\\left(x^i\\right)=\\arg \\max _\\theta \\log \\prod_{i=1}^m P_\\theta\\left(x^i\\right) \\\\ \u0026=\\arg \\max _\\theta \\sum_{i=1}^m \\log P_\\theta\\left(x^i\\right) \\approx \\arg \\max _\\theta E_{x \\sim P_{\\text {data }}}\\left[\\log P_\\theta(x)\\right] \\\\ \u0026=\\arg \\max _\\theta \\int_x P_{\\text {data }}(x) \\log P_\\theta(x) d x-\\int_x P_{\\text {data }}(x) \\log P_{\\text {data }}(x) d x \\\\ \u0026=\\arg \\max _\\theta \\int_x P_{\\text {data }}(x) \\log \\frac{P_\\theta(x)}{P_{\\text {data }}(x)} d x=\\arg \\min _\\theta K L\\left(P_{\\text {data }} \\| P_\\theta\\right) \\end{aligned} $$VAE $$ P_{\\theta}(x) = \\int_{z} P(z)P_{\\theta}(x|z)dz $$Lower bound of $\\log p(x)$ $$ \\begin{aligned} \\log P_{\\theta} (x) \u0026= \\int_{z}q(z|x)\\log P(x)dz, \\quad \\text{ $q(z|x)$ can be any distribution} \\\\ \u0026= \\int_{z}q(z|x)\\log (\\frac{P(z, x)}{P(z|x)}) dz \\\\ \u0026 = \\int_{z}q(z|x)\\log (\\frac{P(z, x)}{q(z|x)} \\frac{q(z| x)}{P(z|x)}) dz \\\\ \u0026= \\int_{z}q(z|x)\\log \\left(\\frac{P(z, x)}{q(z|x)}\\right)dz + \\underbrace{ \\int_{z}q(z|x) \\left(\\frac{q(z| x)}{P(z|x)}\\right) dz}_{\\geq 0} \\\\ \u0026\\geq \\int_{z}q(z|x)\\log \\left(\\frac{P(z, x)}{q(z|x)}\\right)dz = \\underbrace{ E_{q(z|x)} \\log \\left[\\frac{P(z, x)}{q(z|x)}\\right]}_{\\text{lower bound}} \\end{aligned} $$Diffusion models $$ P_{\\theta}(x_0) = \\int_{x_1:x_T} P(x_T) P_{\\theta}(x_{T-1}|x_T) \\cdots P_{\\theta}(x_{t-1}|x_t) \\cdots P_{\\theta}(x_{0}|x_1) d x_1:x_T $$$$ E_{q(x_1:x_T|x_0)} \\log \\left[\\frac{P(x_0:x_T)}{q(x_1:x_T|x_0)}\\right] $$$$ q(x_1:x_T|x_0) = q(x_1|x_0) q(x_2|x_1) \\cdots q(x_T|x_{T-1}) $$$$ \\begin{aligned} E_{q(x_1:x_T|x_0)} \\log \\left[\\frac{P(x_0:x_T)}{q(x_1:x_T|x_0)}\\right] = E_{q(x_1|x_0)}[\\log P(x_0|x_1)] - KL\\left(q(x_T|x_0)||P(x_T)\\right) - \\sum_{t=2}^{T}E_{q(x_t|x_0)}\\left[KL\\left(q(x_{t-1}|x_t, x_0)||P(x_{t-1}|x_0) \\right) \\right] \\end{aligned} $$$$ q(x_{t-1}|x_t, x_0) = \\frac{q(x_t|x_{t-1}, x_0)q(x_{t-1}|x_0)}{q(x_t|x_0)} $$$$ q(x_{t-1}|x_t, x_0) \\propto \\mathcal{N}(x_{t-1}; \\underbrace{\\frac{\\sqrt \\alpha_t (1 - \\overline{a}_{t-1})x_t + \\sqrt{\\overline{\\alpha}_{t-1}} (1 - \\overline{a}_{t}) x_0 }{1 - \\overline{\\alpha}_t}}_{\\mu_{q}(x_t, x_0)}, \\underbrace{\\frac{(1 - \\alpha_t)(1 - \\overline{a}_{t-1})}{1 - \\overline{\\alpha}_{t}}I}_{\\Sigma_{q}(t)}) $$Pytorch Implementation https://colab.research.google.com/drive/1sjy9odlSSy0RBVgMTgP7s99NXsqglsUL?usp=sharing#scrollTo=Ed12NNXPtDon\nReferences DDPM: Ho, J., Jain, A., \u0026 Abbeel, P. (2020). Denoising diffusion probabilistic models. Advances in neural information processing systems, 33, 6840-6851. https://www.youtube.com/watch?v=ifCDXFdeaaM\nhttps://www.youtube.com/watch?v=a4Yfz2FxXiY\u0026t=1585s\n","wordCount":"773","inLanguage":"en","datePublished":"2024-09-03T11:54:04+08:00","dateModified":"2024-09-03T11:54:04+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://lif323.github.io/posts/post-23/"},"publisher":{"@type":"Organization","name":"lif323","logo":{"@type":"ImageObject","url":"https://lif323.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://lif323.github.io/ accesskey=h title="lif323 (Alt + H)">lif323</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">Diffusion Models</h1><div class=post-meta><span title='2024-09-03 11:54:04 +0800 +0800'>September 3, 2024</span></div></header><div class=post-content>$$
X_0 \rightarrow \cdots \rightarrow X_{t} \rightarrow \cdots \rightarrow X_{T}
$$$$
X_T \rightarrow \cdots \rightarrow X_{t} \rightarrow \cdots \rightarrow X_{0}
$$<p>$X_T$: noise
$X_0$: original sample</p><h1 id=vae-vs-diffusion-model>VAE vs. Diffusion model<a hidden class=anchor aria-hidden=true href=#vae-vs-diffusion-model>#</a></h1><p><img loading=lazy src=image-1.png alt="alt text">
In diffusion model, the process of adding noise is similar with encoder in VAE, except that it is not learnable. The process of denoise is similar with decoder in VAE.</p><h1 id=training-in-diffusion-model>Training in Diffusion model<a hidden class=anchor aria-hidden=true href=#training-in-diffusion-model>#</a></h1><p><img loading=lazy src=image.png alt="alt text">
$\mathbf{\epsilon}_{\theta}$ is a noise predictor. It take as input the noised image, and time step $t$ to predict the noise.</p><h1 id=inference-in-diffusion-model>Inference in Diffusion model<a hidden class=anchor aria-hidden=true href=#inference-in-diffusion-model>#</a></h1><p><img loading=lazy src=image-2.png alt="alt text">
Notably, after removing the noise, additional noise $\mathbf{z}$ is added.</p><h1 id=forward-process>Forward Process<a hidden class=anchor aria-hidden=true href=#forward-process>#</a></h1><p>The forward process is one where noise is gradually added to the original distribution of the image $x_0 \sim q(x_0)$.</p><p>The distribution between adjacent time steps is given as follows, where $\beta_t$ is a predefined parameter that increases gradually with each time step.</p>$$
q(x_t| x_{t-1}) = \mathcal{N}(x_t; \sqrt{1 - \beta_{t}}x_{t-1}, \beta_{t}\mathbf{I})
$$$$
\begin{aligned}
x_t = \sqrt{1 - \beta_t} x_{t-1} + \sqrt{\beta_t}\epsilon_{t-1}, \text{where } \epsilon_t \sim \mathcal{N}(0, \mathbf{I})
\end{aligned}
$$$$
\begin{aligned}
x_t &= \sqrt{\alpha_t} x_{t-1} + \sqrt{1 - \alpha_t}\epsilon_{t-1} \\
&= \sqrt{\alpha_t} (\sqrt{\alpha_{t-1}} x_{t-2} + \sqrt{1 - \alpha_{t-1}}\epsilon_{t-2}) + \sqrt{1 - \alpha_t}\epsilon_{t-1} \\
&= \sqrt{\alpha_{t}\alpha_{t-1}} x_{t-2} + \sqrt{\alpha_{t}(1 - \alpha_{t-1})} \epsilon_{t-2} + \sqrt{1 - \alpha_{t}} \epsilon_{t-1}\\
\end{aligned}
$$<p>Since the variance of $\mathcal{N}_1 + \mathcal{N}_2$ is $\sigma_1 + \sigma_2$, we have $\sqrt{\alpha_{t}(1 - \alpha_{t-1})} \epsilon_{t-2} + \sqrt{1 - \alpha_{t}} \epsilon_{t-1} \sim \mathcal{N}(0, (1-\alpha_t \alpha_{t-1})\mathbf{I})$.</p>$$
\begin{aligned}
x_{t} &= \sqrt{\alpha_{t}\alpha_{t-1}} x_{t-2} + \sqrt{1 - \alpha_{t}\alpha_{t-1}} \epsilon\\
&\vdots\\
x_{t} &= \sqrt{\bar{\alpha}_{t}} x_{0} + \sqrt{1 - \bar{\alpha}_{t}} \epsilon \quad \bar{\alpha}_{t} = \prod_{s=1}^{t}\alpha_{s}
\end{aligned}
$$$$
q(x_t|x_0) = \mathcal{N}(x_t; \sqrt{\bar{\alpha}_{t}} x_{0}, (1 - \bar{\alpha}_{t}) \mathbf{I})
$$<p>Based on the above equation, we can conveniently obtain the sample at time step $t$.</p><h1 id=reverse-process>Reverse Process<a hidden class=anchor aria-hidden=true href=#reverse-process>#</a></h1>$$
\begin{aligned}
q(x_{t-1}|x_{t}, x_0) &= \frac{q(x_{t-1}, x_{t}, x_0)}{q(x_{t}, x_0)} \\
&=\frac{q(x_t|x_{t-1}, x_0)q(x_{t-1}|x_0)q(x_0)}{q(x_{t}|x_0) q(x_0)} \\
&=\frac{q(x_t|x_{t-1}, x_0)q(x_{t-1}|x_0)}{q(x_{t}|x_0)}
\end{aligned}
$$<p>where, $q(x_t|x_{t-1}, x_0) = q(x_t|x_{t-1})$ which is based on markov assumption.</p>$$
\begin{aligned}
q(x_{t-1}|x_{t}, x_{0}) &= \frac{q(x_{t}|x_{t-1}, x_{0}) q(x_{t-1} | x_{0})}{q(x_{t}|x_{0})} \\
&\propto \exp ( (- \frac{(x_t - \sqrt{1 - \beta_{t}}x_{t-1})^2}{2\beta_{t}}) + (- \frac{(x_{t-1} - \sqrt{\bar{\alpha}_{t-1}}x_{0})^2}{2(1 - \bar{\alpha}_{t-1})}) - (- \frac{(x_{t} - \sqrt{\bar{\alpha}_{t}}x_{0})^2}{2(1 - \bar{\alpha}_{t})}) )\\
&\propto \exp \left( -\frac{1}{2}\cdot ( (\frac{\alpha_{t}}{\beta_{t}} + \frac{1}{1 - \bar{a}_{t-1}}) x^{2}_{t-1} + (\frac{-2 \sqrt{\alpha_{t}} x_{t}}{\beta_{t}} + \frac{-2\sqrt{\bar{\alpha}_{t-1}} x_{0}}{1 - \bar{\alpha}_{t-1}})x_{t-1} - C(x_t, x_0) ) \right)
\end{aligned}
$$$$
\begin{aligned}
a &= \frac{\alpha_{t}}{\beta_{t}} + \frac{1}{1 - \bar{a}_{t-1}} \\
b &= \frac{-2 \sqrt{\alpha_{t}} x_{t}}{\beta_{t}} + \frac{-2\sqrt{\bar{\alpha}_{t-1}} x_{0}}{1 - \bar{\alpha}_{t-1}} \\
\end{aligned}
$$$$
\begin{aligned}
\mu = - \frac{b}{2a} = \frac{\sqrt{\alpha_{t}}(1 - \bar{\alpha}_{t-1})}{1 - \bar{\alpha}_{t} } x_{t} + \frac{(1 - \alpha_{t}) \sqrt{\bar{\alpha}_{t-1}}}{1 - \bar{\alpha}_{t}} x_{0} \\
\end{aligned}
$$$$ x_0 = \frac{1}{\sqrt{\bar{\alpha}_{t}}} (x_{t} - \sqrt{1 - \bar{\alpha}_{t}} \epsilon)$$$$
\mu = \frac{1}{\sqrt{\bar{\alpha}_{t}}} (x_t - \frac{1 - \alpha_{t}}{\sqrt{1 - \bar{\alpha}_{t}}} \epsilon )
$$<p>Since $\Sigma$ is only related to $\beta$, it is a constant.</p>$$
q(x_{t-1}|x_t, x_0) \propto \mathcal{N}(x_{t-1};
\underbrace{\frac{\sqrt \alpha_t (1 - \overline{a}_{t-1})x_t + \sqrt{\overline{\alpha}_{t-1}} (1 - \overline{a}_{t}) x_0 }{1 - \overline{\alpha}_t}}_{\mu_{q}(x_t, x_0)},
\underbrace{\frac{(1 - \alpha_t)(1 - \overline{a}_{t-1})}{1 - \overline{\alpha}_{t}}I}_{\Sigma_{q}(t)})
$$<h1 id=loss-function-of-ddm>Loss function of DDM<a hidden class=anchor aria-hidden=true href=#loss-function-of-ddm>#</a></h1><h2 id=aim-of-image-generation>Aim of image generation<a hidden class=anchor aria-hidden=true href=#aim-of-image-generation>#</a></h2><p>Let $z$ be the latent space, then a neural network $G$ take $z$ as input and output a image $x$, they want the distribution of $x$ to be as close as with the real image generation.</p>$$
\theta^{*} = \argmax_{\theta}\prod_{i=1}^{m}P_{\theta}(x^i)
$$$$
\begin{aligned}
& \theta^*= \arg \max _\theta \prod_{i=1}^m P_\theta\left(x^i\right)=\arg \max _\theta \log \prod_{i=1}^m P_\theta\left(x^i\right) \\
&=\arg \max _\theta \sum_{i=1}^m \log P_\theta\left(x^i\right) \approx \arg \max _\theta E_{x \sim P_{\text {data }}}\left[\log P_\theta(x)\right] \\
&=\arg \max _\theta \int_x P_{\text {data }}(x) \log P_\theta(x) d x-\int_x P_{\text {data }}(x) \log P_{\text {data }}(x) d x \\
&=\arg \max _\theta \int_x P_{\text {data }}(x) \log \frac{P_\theta(x)}{P_{\text {data }}(x)} d x=\arg \min _\theta K L\left(P_{\text {data }} \| P_\theta\right)
\end{aligned}
$$<h2 id=vae>VAE<a hidden class=anchor aria-hidden=true href=#vae>#</a></h2>$$
P_{\theta}(x) = \int_{z} P(z)P_{\theta}(x|z)dz
$$<h2 id=lower-bound-of-log-px>Lower bound of $\log p(x)$<a hidden class=anchor aria-hidden=true href=#lower-bound-of-log-px>#</a></h2>$$
\begin{aligned}
\log P_{\theta} (x) &= \int_{z}q(z|x)\log P(x)dz, \quad \text{ $q(z|x)$ can be any distribution} \\
&= \int_{z}q(z|x)\log (\frac{P(z, x)}{P(z|x)}) dz \\
& = \int_{z}q(z|x)\log (\frac{P(z, x)}{q(z|x)} \frac{q(z| x)}{P(z|x)}) dz \\
&= \int_{z}q(z|x)\log \left(\frac{P(z, x)}{q(z|x)}\right)dz + \underbrace{ \int_{z}q(z|x) \left(\frac{q(z| x)}{P(z|x)}\right) dz}_{\geq 0} \\
&\geq \int_{z}q(z|x)\log \left(\frac{P(z, x)}{q(z|x)}\right)dz = \underbrace{ E_{q(z|x)} \log \left[\frac{P(z, x)}{q(z|x)}\right]}_{\text{lower bound}}
\end{aligned}
$$<h2 id=diffusion-models>Diffusion models<a hidden class=anchor aria-hidden=true href=#diffusion-models>#</a></h2>$$
P_{\theta}(x_0) = \int_{x_1:x_T} P(x_T) P_{\theta}(x_{T-1}|x_T) \cdots P_{\theta}(x_{t-1}|x_t) \cdots P_{\theta}(x_{0}|x_1) d x_1:x_T
$$$$
E_{q(x_1:x_T|x_0)} \log \left[\frac{P(x_0:x_T)}{q(x_1:x_T|x_0)}\right]
$$$$
q(x_1:x_T|x_0) = q(x_1|x_0) q(x_2|x_1) \cdots q(x_T|x_{T-1})
$$$$
\begin{aligned}
E_{q(x_1:x_T|x_0)} \log \left[\frac{P(x_0:x_T)}{q(x_1:x_T|x_0)}\right] = E_{q(x_1|x_0)}[\log P(x_0|x_1)] - KL\left(q(x_T|x_0)||P(x_T)\right) - \sum_{t=2}^{T}E_{q(x_t|x_0)}\left[KL\left(q(x_{t-1}|x_t, x_0)||P(x_{t-1}|x_0) \right) \right]
\end{aligned}
$$$$
q(x_{t-1}|x_t, x_0) = \frac{q(x_t|x_{t-1}, x_0)q(x_{t-1}|x_0)}{q(x_t|x_0)}
$$$$
q(x_{t-1}|x_t, x_0) \propto \mathcal{N}(x_{t-1};
\underbrace{\frac{\sqrt \alpha_t (1 - \overline{a}_{t-1})x_t + \sqrt{\overline{\alpha}_{t-1}} (1 - \overline{a}_{t}) x_0 }{1 - \overline{\alpha}_t}}_{\mu_{q}(x_t, x_0)},
\underbrace{\frac{(1 - \alpha_t)(1 - \overline{a}_{t-1})}{1 - \overline{\alpha}_{t}}I}_{\Sigma_{q}(t)})
$$<h1 id=pytorch-implementation>Pytorch Implementation<a hidden class=anchor aria-hidden=true href=#pytorch-implementation>#</a></h1><p><a href="https://colab.research.google.com/drive/1sjy9odlSSy0RBVgMTgP7s99NXsqglsUL?usp=sharing#scrollTo=Ed12NNXPtDon">https://colab.research.google.com/drive/1sjy9odlSSy0RBVgMTgP7s99NXsqglsUL?usp=sharing#scrollTo=Ed12NNXPtDon</a></p><h1 id=references>References<a hidden class=anchor aria-hidden=true href=#references>#</a></h1><p>DDPM: Ho, J., Jain, A., & Abbeel, P. (2020). Denoising diffusion probabilistic models. Advances in neural information processing systems, 33, 6840-6851.
<a href="https://www.youtube.com/watch?v=ifCDXFdeaaM">https://www.youtube.com/watch?v=ifCDXFdeaaM</a></p><p><a href="https://www.youtube.com/watch?v=a4Yfz2FxXiY&amp;t=1585s">https://www.youtube.com/watch?v=a4Yfz2FxXiY&amp;t=1585s</a></p></div><footer class=post-footer><ul class=post-tags></ul></footer><script src=https://giscus.app/client.js data-repo=lif323/lif323.github.io data-repo-id=R_kgDOLtjKFA data-category=Announcements data-category-id=DIC_kwDOLtjKFM4Ce08J data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=light data-lang=en crossorigin=anonymous async></script></article></main><footer class=footer><span>&copy; 2025 <a href=https://lif323.github.io/>lif323</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>
<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>CoRTX ICLR 2023 | lif323</title>
<meta name=keywords content><meta name=description content="Before introducing this work, I will first present the Real-time explainer (RTX) framework. RTX is a one-feed-forward explainer that can generate model explanations more efficiently. A major limitation of existing RTX approaches is their reliance on a large number of explanation labels. In my view, RTX is a neural network that generates explanations but like other domains, it also requires substantial data for training.
However, due to limited computational resources and constrained human efforts. accurate explanation labels are difficult to obtain. To address this issue, thie paper proposes the Contrastive Real-Time eXplanation (CoRTX) method. CoRTX trains an encoder using contrastive learning to learn latent explanations in a self-supervised manner, thereby allevating the challenge of data scarcity."><meta name=author content><link rel=canonical href=https://lif323.github.io/posts/post-31/><link crossorigin=anonymous href=/assets/css/stylesheet.1d23bc8761bb8a516d01801663a24eeedbf97720019a7ddc0fc9ff29a2a8730d.css integrity="sha256-HSO8h2G7ilFtAYAWY6JO7tv5dyABmn3cD8n/KaKocw0=" rel="preload stylesheet" as=style><link rel=icon href=https://lif323.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://lif323.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://lif323.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://lif323.github.io/apple-touch-icon.png><link rel=mask-icon href=https://lif323.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://lif323.github.io/posts/post-31/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"\\[",right:"\\]",display:!0},{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],throwOnError:!1})})</script><meta property="og:title" content="CoRTX ICLR 2023"><meta property="og:description" content="Before introducing this work, I will first present the Real-time explainer (RTX) framework. RTX is a one-feed-forward explainer that can generate model explanations more efficiently. A major limitation of existing RTX approaches is their reliance on a large number of explanation labels. In my view, RTX is a neural network that generates explanations but like other domains, it also requires substantial data for training.
However, due to limited computational resources and constrained human efforts. accurate explanation labels are difficult to obtain. To address this issue, thie paper proposes the Contrastive Real-Time eXplanation (CoRTX) method. CoRTX trains an encoder using contrastive learning to learn latent explanations in a self-supervised manner, thereby allevating the challenge of data scarcity."><meta property="og:type" content="article"><meta property="og:url" content="https://lif323.github.io/posts/post-31/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-09-25T09:54:31+08:00"><meta property="article:modified_time" content="2024-09-25T09:54:31+08:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="CoRTX ICLR 2023"><meta name=twitter:description content="Before introducing this work, I will first present the Real-time explainer (RTX) framework. RTX is a one-feed-forward explainer that can generate model explanations more efficiently. A major limitation of existing RTX approaches is their reliance on a large number of explanation labels. In my view, RTX is a neural network that generates explanations but like other domains, it also requires substantial data for training.
However, due to limited computational resources and constrained human efforts. accurate explanation labels are difficult to obtain. To address this issue, thie paper proposes the Contrastive Real-Time eXplanation (CoRTX) method. CoRTX trains an encoder using contrastive learning to learn latent explanations in a self-supervised manner, thereby allevating the challenge of data scarcity."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://lif323.github.io/posts/"},{"@type":"ListItem","position":2,"name":"CoRTX ICLR 2023","item":"https://lif323.github.io/posts/post-31/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"CoRTX ICLR 2023","name":"CoRTX ICLR 2023","description":"Before introducing this work, I will first present the Real-time explainer (RTX) framework. RTX is a one-feed-forward explainer that can generate model explanations more efficiently. A major limitation of existing RTX approaches is their reliance on a large number of explanation labels. In my view, RTX is a neural network that generates explanations but like other domains, it also requires substantial data for training.\nHowever, due to limited computational resources and constrained human efforts. accurate explanation labels are difficult to obtain. To address this issue, thie paper proposes the Contrastive Real-Time eXplanation (CoRTX) method. CoRTX trains an encoder using contrastive learning to learn latent explanations in a self-supervised manner, thereby allevating the challenge of data scarcity.\n","keywords":[],"articleBody":"Before introducing this work, I will first present the Real-time explainer (RTX) framework. RTX is a one-feed-forward explainer that can generate model explanations more efficiently. A major limitation of existing RTX approaches is their reliance on a large number of explanation labels. In my view, RTX is a neural network that generates explanations but like other domains, it also requires substantial data for training.\nHowever, due to limited computational resources and constrained human efforts. accurate explanation labels are difficult to obtain. To address this issue, thie paper proposes the Contrastive Real-Time eXplanation (CoRTX) method. CoRTX trains an encoder using contrastive learning to learn latent explanations in a self-supervised manner, thereby allevating the challenge of data scarcity.\nThe overview of the CoRTX framework is as follows: Explanation-oriented Data Augmentation: The intuition behind data augmentation is that similar data should have similar explanations. In this paper, $\\mathbf{x}^{+}$ is the positive instance for the anchor data instance $\\mathbf{x}$. $\\mathbf{x}^{+}$ is generated by perturbating $\\mathbf{x}$, and the explanations of $\\mathbf{x}^{+}$ and $\\mathbf{x}$ should be similar.\n$$ \\mathbf{x}^{+} = \\mathbf{S}_i \\odot \\boldsymbol{x}+\\left(\\mathbf{1}-\\mathbf{S}_i\\right) \\odot \\boldsymbol{x}_r, \\mathbf{S}_i \\sim \\mathcal{B}(M, \\lambda), 1 \\leq i \\leq m, $$ where $\\mathbf{S}_{i}$ is sampled from an M-dim binomial distribution, and $\\mathbf{x}_r$ is the reference value.\nContrastive Loss: Let $\\mathbf{h}_i = g(x_i | \\theta_g)$, $\\tilde{\\mathbf{h}}^{+}_{i} = g(\\tilde{\\mathbf{x}}^{+}_i | \\theta_g)$ be the latent explanation of the positive pair, and $\\mathbf{h}_i$, $\\mathbf{h}_j = g(\\mathbf{x}_j | \\theta_g)$ be the latent explanation for a negative pair.\n$$ \\mathcal{L}_g=-\\log \\frac{\\exp \\left(\\boldsymbol{h}_i \\cdot \\tilde{\\boldsymbol{h}}_i^{+} / \\tau\\right)}{\\sum_{j=1}^N \\exp \\left(\\boldsymbol{h}_i \\cdot \\boldsymbol{h}_j / \\tau\\right)} $$Fine-tuning the Explanation Head: They leverage a small number of explanation labels to fine-tune the explanation head $\\mathbf{\\eta}(\\cdot|\\theta_{\\eta})$.\nThey designed two tasks along with their corresponding loss functions: (1) Feature Attribution Task: this task aims to test the explanation performance on feature attribution. (2) Feature Importance Ranking Task: this task aims to evaluate the explanation on feature ranking index.\nCODE: The pseudocode is as follows:\nfor epoch in range(n_epoch): # Train the encoder for one epoch. for data_i in data_loader: optimize encoder(data_i) if epoch % 5 == 0: # Train the explanation head until convergence. for epoch_i in range(n_explanation_epoch) optimize explanation_head(encoder(data_i)) References Chuang, Y. N., Wang, G., Yang, F., Zhou, Q., Tripathi, P., Cai, X., \u0026 Hu, X. (2023). Cortx: Contrastive framework for real-time explanation. arXiv preprint arXiv:2303.02794.\n","wordCount":"382","inLanguage":"en","datePublished":"2024-09-25T09:54:31+08:00","dateModified":"2024-09-25T09:54:31+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://lif323.github.io/posts/post-31/"},"publisher":{"@type":"Organization","name":"lif323","logo":{"@type":"ImageObject","url":"https://lif323.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://lif323.github.io/ accesskey=h title="lif323 (Alt + H)">lif323</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">CoRTX ICLR 2023</h1><div class=post-meta><span title='2024-09-25 09:54:31 +0800 +0800'>September 25, 2024</span></div></header><div class=post-content><p>Before introducing this work, I will first present the Real-time explainer (RTX) framework. RTX is a one-feed-forward explainer that can generate model explanations more efficiently. A major limitation of existing RTX approaches is their reliance on a large number of explanation labels. In my view, RTX is a neural network that generates explanations but like other domains, it also requires substantial data for training.</p><p>However, due to limited computational resources and constrained human efforts. accurate explanation labels are difficult to obtain. To address this issue, thie paper proposes the Contrastive Real-Time eXplanation (CoRTX) method. CoRTX trains an encoder using contrastive learning to learn latent explanations in a self-supervised manner, thereby allevating the challenge of data scarcity.</p><p>The overview of the CoRTX framework is as follows:
<img loading=lazy src=image.png alt="alt text"></p><p><strong>Explanation-oriented Data Augmentation:</strong> The intuition behind data augmentation is that similar data should have similar explanations. In this paper, $\mathbf{x}^{+}$ is the positive instance for the anchor data instance $\mathbf{x}$. $\mathbf{x}^{+}$ is generated by perturbating $\mathbf{x}$, and the explanations of $\mathbf{x}^{+}$ and $\mathbf{x}$ should be similar.</p>$$
\mathbf{x}^{+} = \mathbf{S}_i \odot \boldsymbol{x}+\left(\mathbf{1}-\mathbf{S}_i\right) \odot \boldsymbol{x}_r, \mathbf{S}_i \sim \mathcal{B}(M, \lambda), 1 \leq i \leq m,
$$<p>where $\mathbf{S}_{i}$ is sampled from an M-dim binomial distribution, and $\mathbf{x}_r$ is the reference value.</p><p><strong>Contrastive Loss:</strong> Let $\mathbf{h}_i = g(x_i | \theta_g)$, $\tilde{\mathbf{h}}^{+}_{i} = g(\tilde{\mathbf{x}}^{+}_i | \theta_g)$ be the latent explanation of the positive pair, and $\mathbf{h}_i$, $\mathbf{h}_j = g(\mathbf{x}_j | \theta_g)$ be the latent explanation for a negative pair.</p>$$
\mathcal{L}_g=-\log \frac{\exp \left(\boldsymbol{h}_i \cdot \tilde{\boldsymbol{h}}_i^{+} / \tau\right)}{\sum_{j=1}^N \exp \left(\boldsymbol{h}_i \cdot \boldsymbol{h}_j / \tau\right)}
$$<p><strong>Fine-tuning the Explanation Head:</strong> They leverage a small number of explanation labels to fine-tune the explanation head $\mathbf{\eta}(\cdot|\theta_{\eta})$.</p><p>They designed two tasks along with their corresponding loss functions:
(1) Feature Attribution Task: this task aims to test the explanation performance on feature attribution.
(2) Feature Importance Ranking Task: this task aims to evaluate the explanation on feature ranking index.</p><p><strong>CODE:</strong> The pseudocode is as follows:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>for</span> epoch <span style=color:#f92672>in</span> range(n_epoch):
</span></span><span style=display:flex><span>    <span style=color:#75715e># Train the encoder for one epoch.</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> data_i <span style=color:#f92672>in</span> data_loader:
</span></span><span style=display:flex><span>        optimize encoder(data_i)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> epoch <span style=color:#f92672>%</span> <span style=color:#ae81ff>5</span> <span style=color:#f92672>==</span> <span style=color:#ae81ff>0</span>:
</span></span><span style=display:flex><span>        <span style=color:#75715e># Train the explanation head until convergence.</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>for</span> epoch_i <span style=color:#f92672>in</span> range(n_explanation_epoch)
</span></span><span style=display:flex><span>            optimize explanation_head(encoder(data_i))
</span></span></code></pre></div><h1 id=references>References<a hidden class=anchor aria-hidden=true href=#references>#</a></h1><p>Chuang, Y. N., Wang, G., Yang, F., Zhou, Q., Tripathi, P., Cai, X., & Hu, X. (2023). Cortx: Contrastive framework for real-time explanation. arXiv preprint arXiv:2303.02794.</p></div><footer class=post-footer><ul class=post-tags></ul></footer><script src=https://giscus.app/client.js data-repo=lif323/lif323.github.io data-repo-id=R_kgDOLtjKFA data-category=Announcements data-category-id=DIC_kwDOLtjKFM4Ce08J data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=light data-lang=en crossorigin=anonymous async></script></article></main><footer class=footer><span>&copy; 2024 <a href=https://lif323.github.io/>lif323</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>
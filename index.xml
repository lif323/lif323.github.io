<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>lif323</title><link>https://lif323.github.io/</link><description>Recent content on lif323</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Thu, 18 Apr 2024 11:24:57 +0800</lastBuildDate><atom:link href="https://lif323.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>Gumbel Softmax</title><link>https://lif323.github.io/posts/gumbel-softmax/</link><pubDate>Thu, 18 Apr 2024 11:24:57 +0800</pubDate><guid>https://lif323.github.io/posts/gumbel-softmax/</guid><description>What is Gubmel-softmax? Gumbel-softmax is an efficient gradient estimator for the non-differentiable sample from a categorical distribution.
Let $z$ be a categorical variable with class probabilities $\pi_1$, $\pi_2$, $\cdots$, $\pi_k$.
The Gumbel-Max trick is an efficient way to draw samples $z$ from a categorical distribution with class probabilities $\pi$: $$ z = \text{one\_hot}(\argmax_{i}\left[g_i + log \pi_i\right]) $$ where $g_1$, $\cdots$, $g_k$ are i.i.d samples drawn from Gumbel(0, 1). The Gubel(0, 1) distribution can be sampled by drawing $u \sim \text{Uniform}(0, 1)$ and computing $g = - \log (- \log (u))$.</description></item><item><title>Notes on the Paper NeurIPS 2023 Evaluating Post Hoc Explanations for Graph Neural Networks via Robustness Analysis</title><link>https://lif323.github.io/posts/notes-on-the-paper-neurips-2023-evaluating-post-hoc-explanations-for-graph-neural-networks-via-robustness-analysis/</link><pubDate>Sat, 13 Apr 2024 12:45:24 +0800</pubDate><guid>https://lif323.github.io/posts/notes-on-the-paper-neurips-2023-evaluating-post-hoc-explanations-for-graph-neural-networks-via-robustness-analysis/</guid><description>This paper focuses on the performance of evaluation methods of Post-hoc Explanations. Current prevailing evalution methods mainly inlcudes two types: Feature Removal methods and Generation-based methods.
This paper hones in on the evaluation of the effectiveness of Post-hoc Explanation evaluation methods. Predominantly, current methodologies fall into two primary classifications: Feature Removal and Generation-based approaches.
Feature Removal operates on the principle of excising salient features identified through explanation mechanisms. The merit of such explanations is quantified by the variance in the model&amp;rsquo;s output pre and post-feature extrication.</description></item></channel></rss>